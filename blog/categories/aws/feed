<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on Aimless</title>
    <link>http://aimless.jp/categories/aws/</link>
    <description>Recent content in Aws on Aimless</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 11 Jun 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://aimless.jp/categories/aws/feed/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>airinterop.jpを支える技術</title>
      <link>http://aimless.jp/blog/archives/2016-06-11-the-technology-to-support-airinterop</link>
      <pubDate>Sat, 11 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-06-11-the-technology-to-support-airinterop</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;2年前から、「airinterop.jp」という非公認ネタサイトを作っています。簡単なウェブサイトくらい気軽に建てられるくらいのスキルは欲しいので。&lt;/p&gt;

&lt;p&gt;例年は、適当にHTMLとCSSを作りVPS上のApacheで公開するだけでした。ですが、今年のairinterop.jpは、製作者のスキル向上に伴い、新しい取り組みを行いました。来年のためにもやったことをメモしておきます&lt;/p&gt;

&lt;h2 id=&#34;webページ公開&#34;&gt;WEBページ公開&lt;/h2&gt;

&lt;p&gt;今年のairinterop.jpは、S3の静的ウェブサイトホスティングを利用しました。&lt;/p&gt;

&lt;p&gt;去年までのairInterop.jpはConoHaで稼働していました。ですが、経費節約を目的にConoHaを解約したため、Apacheやnginxに頼ることができません。現時点で常時稼働しているVPSは、リモート艦これ用のさくらのVPS for Windows Serverだけです。ですが、このVPSは、艦これのせいでCPUが常時90%を超えているため、サービスを公開するのに不向きです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ネタサイトのために再びVPSを借りるのは馬鹿らしいので、S3の静的ウェブサイトホスティングでリリースしました&lt;/p&gt;

&lt;h2 id=&#34;参加者カウンタ&#34;&gt;参加者カウンタ&lt;/h2&gt;

&lt;p&gt;「airinterop.jpの参加者が可視化されたら面白くね？」という思いつきから、Doorkeeperなどのイベント登録サイトのように、参加者のTwitterアイコンを表示するようにしました。公式サイトも来場者数を公表していますし。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;静的ウェブサイトホスティングにしてしまったので、サーバ側でTwitterアイコンを動的に描画することはできません。そこで、API Gateway＋mithril.jsを使って、クライアント側で動的に描画することにしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-04.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;API Gatewayが返すデータはMockを使いました。DynamoDBやLambdaからデータを返すよりも安上がりで実装も簡単です。Lambdaを利用して#airinteropのハッシュタグをツイートした人のデータを作成し、そのデータを使ってAPI GatewayのMock を更新しました。&lt;/p&gt;

&lt;p&gt;初めてaws-sdkでAPI Gatewayを操作したので、updateIntegrationResponseしたあとにcreateDeploymentすることに気が付くのに時間がかかりました。その結果、Mockのデータは更新されているのにAPI Gatewayが返すデータが古いままという事象に数時間悩みました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;function(body,callback){
  var apigateway = new AWS.APIGateway();
  var params = {
    httpMethod: &#39;GET&#39;, /* required */
    resourceId: &#39;xxxxxxxxxx&#39;, /* required */
    restApiId: &#39;xxxxxxxxxx&#39;, /* required */
    statusCode: &#39;200&#39;, /* required */
    patchOperations: [
      {
        op: &#39;replace&#39;,
        path: &#39;/responseTemplates/application~1json;charset=UTF-8&#39;,
        value: JSON.stringify(body)
      }
    ]
  };
  apigateway.updateIntegrationResponse(params, function(err, data) {
    var params = {
      restApiId: &#39;xxxxxxxxxx&#39;, /* required */
      stageName: &#39;prod&#39;, /* required */
    }
    apigateway.createDeployment(params, function(err, data) {
      if (err) {
        console.log(err, err.stack);
      } else {
        callback()  
      }
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mithril.jsは以下のような簡単なコードです。API Gatewayから取得したjsonをデータバインディング用の配列に格納し格納し、Viewでその配列を描画します。なお、いまだにControllerとView Model、Modelの使い分けがわかりません。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var register = {}

register.vm = {
    init: function(){
    
        register.vm.listAry = m.prop([])
        m.request({
            Method:&amp;quot;GET&amp;quot;,
            url:&amp;quot;https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod&amp;quot;,
        }).then(function(responce){
            for (var i = 0; i&amp;lt; responce.length; i++){
                register.vm.listAry().push(responce[i])
            }
        });
    }        
};

register.controller = function () {
    register.vm.init()
}

register.view = function(){
    return [
        m(&amp;quot;h2&amp;quot;,register.vm.listAry().length + &#39;人の参加者&#39;),
        register.vm.listAry().map(function(data){
            return [
                m(&amp;quot;div&amp;quot;,{class:&amp;quot;resister-icon&amp;quot;},[
                    m(&amp;quot;img&amp;quot;,{src:data.profile_image_url})
                ])
            ]
        })        
    ]
}

m.mount(document.getElementById(&amp;quot;twit-register&amp;quot;), {
  controller: register.controller,
  view: register.view
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参加者の情報は自動で定期更新されるべきですので、Cloudwatch Eventsを使って、MOCKのデータ更新用Lambdaを定期発火しました。lambdaの定期実行は、Lambda側で設定することもできますが、Cloudwatch Eventsを使ったほうがcrontabのように一覧性が高くなるので好きです。&lt;/p&gt;

&lt;h2 id=&#34;airinteopのツイート分析&#34;&gt;#airinteopのツイート分析&lt;/h2&gt;

&lt;p&gt;会期中、本家のBest of show awardsのようなことをやりたくなりました。そこで、Twitter APを使って#airinteropのツイートを収集し、最もリツイート数の多いツイートを、勝手にBest of Airinterop Awardとして表彰しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-03.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;手作業で集計するのは非常に大変なので、node.jsとtwitを使って集計スクリプトを作りこみました。とりあえず集計優先で動くコードを書きましたが、next_resultsがなくなるまで検索を続ける処理について、もう少し良いアルゴリズムがありそうな気がします。&lt;/p&gt;

&lt;p&gt;以下のスクリプトを動かすと、Retweet数トップ5のツイートを埋め込むためのHTMLコード
を取得することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var Twit = require(&#39;twit&#39;);
var async = require(&#39;async&#39;);

var T = new Twit({
});

var loop = 20
var loopAry = []
for (var k = 0; k&amp;lt;loop; k++){
  loopAry.push(k)
}
  
var regex = new RegExp(/max_id=(.+)&amp;amp;q=/)
var max_id = &amp;quot;&amp;quot;
var body = []
var param = { 
  q: &#39;#airinterop&#39;, 
  count:100
}

async.eachSeries(loopAry,
  function(item,callback){  
    if (max_id != &amp;quot;&amp;quot;){
      param.max_id = max_id
    } 
       
    T.get(&#39;search/tweets&#39;, param, function(err, data){
      var statuses = data[&#39;statuses&#39;];
      for (var i = 0; i &amp;lt; statuses.length ; i++) {
        // retweetは除く
        if(!statuses[i].retweeted_status){
          var obj = {};
          obj.created_at = statuses[i].created_at;
          obj.screen_name = statuses[i].user.screen_name
          obj.id_str = statuses[i].id_str
          obj.retweet_count = statuses[i].retweet_count;
          obj.text = statuses[i].text;
          body.push(obj)                        
        }
      };
      if (data.search_metadata.next_results){
        max_id = data.search_metadata.next_results.match(regex)[1]          
        callback();
      } else {
        var fakeErr = new Error();
        fakeErr.break = true;
        return callback(fakeErr);
      }
    })    
  },
  function(err){
    body.sort(function(a,b){
      if(a.retweet_count &amp;lt; b.retweet_count ) return 1;
        if(a.retweet_count &amp;gt; b.retweet_count ) return -1;
        return 0
    })
      
    var awards = []
    for (var j = 0; j &amp;lt; 5;j++){
      awards.push(body[j])
    }
      
    var paramOembed ={}
    
    async.eachSeries(awards,function(item,callback){
      paramOembed = {
        id:item.id_str
      }
                
      T.get(&#39;statuses/oembed&#39;, paramOembed, function(err, data){
        console.log(data)
        callback()
      })
    })
  }
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;来年への意気込み&#34;&gt;来年への意気込み&lt;/h2&gt;

&lt;p&gt;来年は何をしましょうか。やりきってしまった感があります。公式サイトを眺めてもネタが思いつきませんので、独自路線に進むしかありません。BOTが流行っているので、えあーいんたろっぷん的な、皆様がつぶやいた面白展示をご案内するBOTを作ってみたいですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Apache Drill を使ってVPC Flow Logsを集計する</title>
      <link>http://aimless.jp/blog/archives/2016-02-14-analysing-vpcflowlogs-by-apachedrill</link>
      <pubDate>Sun, 14 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-14-analysing-vpcflowlogs-by-apachedrill</guid>
      <description>

&lt;h2 id=&#34;vpc-flow-logsを集計する&#34;&gt;VPC FLow Logsを集計する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader/&#34;&gt;flowlogs-readerを使って、VPC Flow Logsをコマンドラインで操作する&lt;/a&gt;にて、flowlogs-readerの標準出力をawkで集計する方法を紹介しました。&lt;/p&gt;

&lt;p&gt;ですが、この方法は自分が意図するシェル芸を考えることが大変です。もう少しスマートなやり方はないものかと考えた結果、Apache Drillを使う方法を思いついたので試してみました。&lt;/p&gt;

&lt;h2 id=&#34;apache-drillのインストール&#34;&gt;Apache Drillのインストール&lt;/h2&gt;

&lt;p&gt;とりあえず使うことを目的としますので、tar.gzをダウンロードして解凍するだけにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget http://ftp.jaist.ac.jp/pub/Apache/drill/drill-1.4.0/Apache-drill-1.4.0.tar.gz
--2016-02-14 19:37:02--  http://ftp.jaist.ac.jp/pub/Apache/drill/drill-1.4.0/Apache-drill-1.4.0.tar.gz
Resolving ftp.jaist.ac.jp (ftp.jaist.ac.jp)... 2001:df0:2ed:feed::feed, 150.65.7.130
Connecting to ftp.jaist.ac.jp (ftp.jaist.ac.jp)|2001:df0:2ed:feed::feed|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 202712816 (193M) [application/x-gzip]
Saving to: ‘Apache-drill-1.4.0.tar.gz’

Apache-drill-1.4.0.tar.gz                 1%[&amp;gt;                                                                              ]   3.25M  5.33MB/s             
Apache-drill-1.4.0.tar.gz               100%[==============================================================================&amp;gt;] 193.32M   743KB/s   in 1m 55s

2016-02-14 19:38:57 (1.68 MB/s) - ‘Apache-drill-1.4.0.tar.gz’ saved [202712816/202712816]

$
$ tar xzvf Apache-drill-1.4.0.tar.gz                                                                                                      
Apache-drill-1.4.0/KEYS
Apache-drill-1.4.0/LICENSE
Apache-drill-1.4.0/README.md
Apache-drill-1.4.0/NOTICE
（中略）
Apache-drill-1.4.0/sample-data/regionsMF/regionsMF_Typed.parquet
Apache-drill-1.4.0/sample-data/regionsSF/regionsSF.parquet
$ cd Apache-drill-1.4.0/
Apache-drill-1.4.0]$
Apache-drill-1.4.0]$ bin/drill-embedded
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0
Feb 14, 2016 7:40:57 PM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.8 2014-04-29 01:25:26...
Apache drill 1.4.0
&amp;quot;drill baby drill&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお、初めはt2.microのEC2で試したのですが、メモリ不足？なのかApache Drillが起動しませんでした。メモリ2Gのconohaで試したところ、無事起動しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ drill-embedded
OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000006e0000000, 1431633920, 0) failed; error=&#39;Cannot allocate memory&#39; (errno=12)
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (malloc) failed to allocate 1431633920 bytes for committing reserved memory.
# An error report file with more information is saved as:
# /tmp/jvm-10501/hs_error.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計元データの作成&#34;&gt;集計元データの作成&lt;/h2&gt;

&lt;p&gt;flowlogs-readerの標準出力をawkでCSV形式にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-13 00:00:00&#39; -e &#39;2016-02-14 00:00:00&#39; | awk -F&amp;quot; &amp;quot; &#39;{print strftime(&amp;quot;%F %T %Z&amp;quot;,$11) &amp;quot;,&amp;quot; $4 &amp;quot;,&amp;quot; $5 &amp;quot;,&amp;quot; $6 &amp;quot;,&amp;quot; $7 &amp;quot;,&amp;quot; $8 &amp;quot;,&amp;quot; $10 &amp;quot;,&amp;quot; $13}&#39; &amp;gt; result.csv    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、CSV形式のままApache Drillで利用すると、以下のような集計できない形になってしまいます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select * from dfs.`/home/xxxxxxxx/result.csv`;                
+------------------------------------------------------------------------------------------------+
|                                            columns                                             |
+------------------------------------------------------------------------------------------------+
| [&amp;quot;time&amp;quot;,&amp;quot;srcaddr&amp;quot;,&amp;quot;dstaddr&amp;quot;,&amp;quot;srcport&amp;quot;,&amp;quot;dstport&amp;quot;,&amp;quot;protocol&amp;quot;,&amp;quot;bytes&amp;quot;,&amp;quot;result&amp;quot;]                   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;44626&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;895&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;44624&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;77&amp;quot;,&amp;quot;ACCEPT&amp;quot;]    |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;54.245.244.135&amp;quot;,&amp;quot;52457&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;56372&amp;quot;,&amp;quot;ACCEPT&amp;quot;]  |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;50.112.250.150&amp;quot;,&amp;quot;49776&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;3262&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;54.245.120.220&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;33586&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;201&amp;quot;,&amp;quot;ACCEPT&amp;quot;]    |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;54.245.244.135&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;52457&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;31877&amp;quot;,&amp;quot;ACCEPT&amp;quot;]  |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;150.67.32.141&amp;quot;,&amp;quot;22&amp;quot;,&amp;quot;39999&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;520&amp;quot;,&amp;quot;ACCEPT&amp;quot;]      |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;50.112.250.150&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;49776&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;5552&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;44629&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;935&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで、CSVファイルの1行目にヘッダを追加し、CSVH形式で保存します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ more /home/xxxxxxxx/result.csvh
time,srcaddr,dstaddr,srcport,dstport,protocol,bytes,result
2016002013 18:33:24 JST,103.246.150.182,172.20.0.10,443,44626,6,895,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,103.246.150.182,44624,443,6,77,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,54.245.244.135,52457,443,6,56372,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,50.112.250.150,49776,443,6,3262,ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、ポート番号の欄に&lt;code&gt;-&lt;/code&gt;が入っていると、ポート番号を数値として扱えなくなるため、sedで&lt;code&gt;-&lt;/code&gt;を0に置換しておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i -e &amp;quot;s/-/0/g&amp;quot; /home/xxxxxxxx/result.csvh  
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計してみる&#34;&gt;集計してみる&lt;/h2&gt;

&lt;p&gt;とりあえずselectしてみましょう。CSVH形式にすると追加したヘッダがカラムになります。これならば集計できますね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select * from dfs.`/home/xxxxxxxx/result.csvh` ;
+--------------------------+------------------+------------------+----------+----------+-----------+--------+---------+
|           time           |     srcaddr      |     dstaddr      | srcport  | dstport  | protocol  | bytes  | result  |
+--------------------------+------------------+------------------+----------+----------+-----------+--------+---------+
| 2016002013 18:33:24 JST  | 103.246.150.182  | 172.20.0.10      | 443      | 44626    | 6         | 895    | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 103.246.150.182  | 44624    | 443      | 6         | 77     | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 54.245.244.135   | 52457    | 443      | 6         | 56372  | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 50.112.250.150   | 49776    | 443      | 6         | 3262   | ACCEPT  |
| 2016002013 18:33:24 JST  | 54.245.120.220   | 172.20.0.10      | 443      | 33586    | 6         | 201    | ACCEPT  |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送信元がVPC内部のアドレス、宛先がVPC外部のアドレス、送信元ポートがウェルノウンポートな通信のバイト数で集計します。VPC外部の端末がサーバの提供するサービスにアクセスしたことによって生じたアウトバウンド通信が対象になるはず。&lt;/p&gt;

&lt;p&gt;上位2件に入った、protocolが41（IPv6）で192.88.99.255宛の通信はいったい何でしょうか。6to4？&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select srcaddr,dstaddr,protocol,srcport,SUM(cast(bytes as INTEGER)) as bytes
. . . . . . . . . . . &amp;gt; from dfs.`/home/xxxxxxxx/result.csvh`    
. . . . . . . . . . . &amp;gt; where srcaddr LIKE &#39;172.20%&#39; AND dstaddr NOT LIKE &#39;172.20%&#39;
. . . . . . . . . . . &amp;gt; AND srcport &amp;lt; 1024
. . . . . . . . . . . &amp;gt; GROUP BY srcaddr,dstaddr,protocol,srcport
. . . . . . . . . . . &amp;gt; ORDER BY bytes desc;
+--------------+-----------------+-----------+----------+--------+
|   srcaddr    |     dstaddr     | protocol  | srcport  | bytes  |
+--------------+-----------------+-----------+----------+--------+
| 172.20.1.52  | 192.88.99.255   | 41        | 0        | 49352  |
| 172.20.0.67  | 192.88.99.255   | 41        | 0        | 48608  |
| 172.20.0.10  | xxx.xxx.xxx.xxx  | 6         | 22       | 20748  |
| 172.20.0.10  | 157.7.236.66    | 17        | 123      | 10488  |
| 172.20.0.20  | 160.16.101.116  | 17        | 123      | 4408   |
| 172.20.0.10  | 129.250.35.250  | 17        | 123      | 1748   |
| 172.20.0.10  | 59.106.180.168  | 17        | 123      | 1748   |
| 172.20.0.10  | 157.7.154.29    | 17        | 123      | 1672   |
| 172.20.0.20  | 60.56.214.78    | 17        | 123      | 1672   |
| 172.20.0.20  | 160.16.201.66   | 17        | 123      | 1672   |
| 172.20.0.20  | 106.187.50.84   | 17        | 123      | 1672   |
| 172.20.0.10  | xxx.xxx.xxx.xxx    | 6         | 22       | 440    |
| 172.20.0.20  | 37.203.214.106  | 6         | 80       | 40     |
| 172.20.0.20  | 107.150.60.74   | 6         | 80       | 40     |
+--------------+-----------------+-----------+----------+--------+
14 rows selected (3.928 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送信元がVPC内部のアドレス、宛先がVPC外部のアドレス、宛先ポートがウェルノウンポートな通信のバイト数で集計します。サーバが、VPC外部のサーバにアクセスしたことによって生じたアウトバウンド通信が対象になるはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select srcaddr,dstaddr,protocol,dstport,SUM(cast(bytes as INTEGER)) as bytes
. . . . . . . . . . . &amp;gt; from dfs.`/home/xxxxxxxx/result.csvh`
. . . . . . . . . . . &amp;gt; where srcaddr LIKE &#39;172.20%&#39; AND dstaddr NOT LIKE &#39;172.20%&#39;
. . . . . . . . . . . &amp;gt; AND dstport &amp;lt; 1024
. . . . . . . . . . . &amp;gt; GROUP BY srcaddr,dstaddr,protocol,dstport
. . . . . . . . . . . &amp;gt; ORDER BY bytes desc;
+--------------+------------------+-----------+----------+-----------+
|   srcaddr    |     dstaddr      | protocol  | dstport  |   bytes   |
+--------------+------------------+-----------+----------+-----------+
| 172.20.0.10  | 103.246.150.154  | 6         | 443      | 21089910  |
| 172.20.0.10  | 27.0.2.250       | 6         | 443      | 16760457  |
| 172.20.0.10  | 103.246.150.182  | 6         | 443      | 16511551  |
| 172.20.0.10  | 54.245.91.49     | 6         | 443      | 2868271   |
| 172.20.0.10  | 54.244.113.28    | 6         | 443      | 2711682   |
| 172.20.0.10  | 54.245.120.220   | 6         | 443      | 1238373   |
| 172.20.0.10  | 50.112.250.150   | 6         | 443      | 913540    |
| 172.20.0.10  | 54.214.50.176    | 6         | 443      | 627718    |
| 172.20.0.10  | 54.245.244.135   | 6         | 443      | 331731    |
| 172.20.1.52  | 192.88.99.255    | 41        | 0        | 49352     |
| 172.20.0.67  | 192.88.99.255    | 41        | 0        | 48608     |
| 172.20.0.10  | 54.239.25.168    | 6         | 443      | 31625     |
| 172.20.0.10  | 157.7.236.66     | 17        | 123      | 10488     |
| 172.20.0.10  | 72.21.214.87     | 6         | 443      | 4655      |
| 172.20.0.20  | 160.16.101.116   | 17        | 123      | 4408      |
| 172.20.0.10  | 59.106.180.168   | 17        | 123      | 1748      |
| 172.20.0.10  | 129.250.35.250   | 17        | 123      | 1748      |
| 172.20.0.20  | 60.56.214.78     | 17        | 123      | 1672      |
| 172.20.0.20  | 160.16.201.66    | 17        | 123      | 1672      |
| 172.20.0.20  | 106.187.50.84    | 17        | 123      | 1672      |
| 172.20.0.10  | 157.7.154.29     | 17        | 123      | 1672      |
| 172.20.0.10  | 108.168.243.150  | 6         | 443      | 1093      |
| 172.20.0.10  | 54.231.224.66    | 6         | 80       | 769       |
| 172.20.0.10  | 54.231.224.10    | 6         | 80       | 613       |
+--------------+------------------+-----------+----------+-----------+
24 rows selected (0.714 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;VPC Flow Logsを分析する手法として、Apache Drillを試しました。CSVファイルに対してmysqlライクなクエリを投げられるのが大変便利だなと思いました。Apache Drillを使っても自分がやりたいことをクエリにしなければなりませんが、シェル芸のワンライナーを考えるよりもmysqlライクなクエリを考える方が簡単です。&lt;/p&gt;

&lt;p&gt;今回利用したVPC Flow Logsはたった3Mです。データ容量がもっと増えた場合にどのような挙動になるのかは別途確認したいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>flowlogs-readerを使って、VPC Flow Logsをコマンドラインで操作する</title>
      <link>http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader</link>
      <pubDate>Tue, 02 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader</guid>
      <description>

&lt;p&gt;VPC Flow Logsを分析、可視化する方法を模索しており、以下のツール・サービスを試しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sumologic&lt;/li&gt;
&lt;li&gt;Splunk&lt;/li&gt;
&lt;li&gt;ElasticSearch&lt;/li&gt;
&lt;li&gt;ElasticSearch Service&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どれも素晴らしいツールなのですが、気軽にログを調査する、集計するといった用途で使うには少々大がかりです。もっと気軽なツールはないかとGithubをさまよった結果、&lt;a href=&#34;https://github.com/obsrvbl/flowlogs-reader&#34;&gt;obsrvbl/flowlogs-reader&lt;/a&gt;というツールを見つけたので試してみました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;READMEに書いてある通りです。ソースからインストールしてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/obsrvbl/flowlogs-reader.git
cd flowlogs-reader
pyenv exec python setup.py develop
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基本操作&#34;&gt;基本操作&lt;/h2&gt;

&lt;p&gt;READMEに従って、&lt;code&gt;flowlogs_reader logGroupName&lt;/code&gt;を実行してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup

Traceback (most recent call last):
（中略）
botocore.exceptions.ClientError: An error occurred (ResourceNotFoundException) when calling the FilterLogEvents operation: The specified log group does not exist.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そんなロググループはないと怒られました。これはリージョンを指定していないことが原因です。デフォルトのリージョンはus-east-1になっていますが、私のAWSアカウントのus-east-1にはlogGroupNameというVPC Flow Logsが存在しません。東京リージョンにはlogGroupNameというVPC Flow Logsが存在していますので、&lt;code&gt;--region&lt;/code&gt;で東京リージョンを指定します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1       
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 51378 6 13 1982 1454337327 1454337447 ACCEPT OK       
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 47354 6 10 1223 1454337327 1454337447 ACCEPT OK      
2 743065858817 eni-63444414 27.0.2.250 172.20.0.10 443 50540 6 10 935 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 47354 443 6 12 1501 1454337327 1454337447 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 27.0.2.250 50539 443 6 12 1501 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 27.0.2.250 50540 443 6 12 1501 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 195.99.212.67 172.20.0.10 53 57627 17 1 77 1454337327 1454337387 REJECT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;出ました！なにこれすごい！&lt;/p&gt;

&lt;h3 id=&#34;時間指定&#34;&gt;時間指定&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;-s&lt;/code&gt;と&lt;code&gt;-e&lt;/code&gt;オプションを使うことで、抽出する範囲を限定することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39;
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44589 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44589 6 10 935 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44591 6 10 935 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 48618 6 7 1079 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44591 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44592 443 6 6 313 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44588 6 9 895 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44592 6 4 306 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 54.245.120.220 48618 443 6 11 2232 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44588 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-98fccfd1 104.216.59.132 172.20.0.106 57664 6379 6 1 40 1454324381 1454324411 REJECT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おおお、すごい。VPC Flow Logs内のstartをもとにフィルタリングしてるようです。&lt;/p&gt;

&lt;h2 id=&#34;ipアドレスで抽出&#34;&gt;IPアドレスで抽出&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;findip&lt;/code&gt;を利用することで、IPアドレスを利用したログの抽出が可能です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup findip 54.245.120.220 --region
 ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39;                                                
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 48618 6 7 1079 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 54.245.120.220 48618 443 6 11 2232 1454324362 1454324415 ACCEPT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;awkで処理する&#34;&gt;AWKで処理する&lt;/h2&gt;

&lt;p&gt;VPC Flow Logsの内容が標準出力されるということは、AWKで自由に編集できるということです。&lt;/p&gt;

&lt;p&gt;まずは、VPC Flow Logsの時刻をJSTに変換、かつ不要なフィールドを削除することで可読性を向上してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39; | awk -F&amp;quot; &amp;quot; &#39;{print strftime(&amp;quot;%F %T %Z&amp;quot;,$11) &amp;quot; &amp;quot; $4 &amp;quot; &amp;quot; $5 &amp;quot; &amp;quot; $6 &amp;quot; &amp;quot;
 $7 &amp;quot; &amp;quot; $10 &amp;quot; &amp;quot; $13}&#39;
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44589 443 1501 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44589 935 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44591 935 ACCEPT
2016-02-01 19:59:22 JST 54.245.120.220 172.20.0.10 443 48618 1079 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44591 443 1501 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44592 443 313 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44588 895 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44592 306 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 54.245.120.220 48618 443 2232 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44588 443 1501 ACCEPT
2016-02-01 19:59:41 JST 104.216.59.132 172.20.0.106 57664 6379 40 REJECT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すごく見やすくなりました。一般的なファイアウォールのログのようです。この形式であればトラブルシュートが簡単ですね。&lt;/p&gt;

&lt;p&gt;どのようなデータを得られるかは、分析の要件をシェル芸で実装できるかどうか次第です。私はシェル芸力が赤ちゃんレベルなので、Google先生に聞きながら、172.20.0.10からのOutbound通信を、通信量が多いホスト順に集計するワンライナーを書いてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 | awk -F&amp;quot; &amp;quot; &#39;{if($4 ~ /^172.20.0.10$/) print $4 &amp;quot; &amp;quot; $5 &amp;quot; &amp;quot; $6 &amp;quot; &amp;quot; $7 &amp;quot; &amp;quot; $10}&#39; | awk -F &amp;quot; &amp;quot; &#39;{ arr[$2] += $5 } END {for
 (i in arr) {print arr[i] &amp;quot;\t&amp;quot; i } }&#39; | sort -nr
1953728 xxx.246.150.182
1513154 xxx.0.2.250
1403416 xxx.2.107.75
585957  xxx.246.150.154
230835  xxx.245.91.49
99516   xxx.245.231.247
68348   xxx.214.251.251
59299   xxx.112.97.146
29665   xxx.245.120.220
2657    xxx.32.102.213
1368    xxx.7.236.66
684     xxx.106.180.168
228     xxx.7.154.29
228     xxx.250.35.250
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おお、できたっぽい！&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;過去触ってきた各種サービスは、VPC Flow Logsを継続的に保管し、傾向を分析、可視化するにはもってこいです。ですが、トラブルシュートなどのスポット用途でログを見たい、分析したいという用途には少々オーバースペックです。そんな人には、&lt;a href=&#34;https://github.com/obsrvbl/flowlogs-reader&#34;&gt;obsrvbl/flowlogs-reader&lt;/a&gt;をお勧めします。気軽ですよ。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sumologicを使ってVPC Flow Logsを可視化する</title>
      <link>http://aimless.jp/blog/archives/2016-01-24-analysing-vpcflowlogs-by-sumologic</link>
      <pubDate>Sun, 24 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-01-24-analysing-vpcflowlogs-by-sumologic</guid>
      <description>

&lt;h2 id=&#34;vpc-flow-logsを可視化したい&#34;&gt;VPC FLow Logsを可視化したい&lt;/h2&gt;

&lt;p&gt;検証環境のVPC Flow Logsを収集、調査、分析するためにElasticSearch Serviceを利用していましたが、利用料をケチるためにt2.microで動かしていたため動作が遅く困っていました。オンプレミスで十分なリソースを積んだElasticSearchを立ててもよかったのですが、目的はログを分析することであって、ElasticSearchを運用することではありません。&lt;/p&gt;

&lt;p&gt;そこで、VPC FLow Logsに対応しており、無料プランのあるログ分析SaaSを調べたところ、&lt;a href=&#34;https://www.sumologic.com/&#34;&gt;sumologic&lt;/a&gt;が見つかりました。Re:Invent2015の会場で相撲を取っていたあのsumologicです。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&#34;https://www.youtube.com/watch?v=WLuH-Rht3nw&#34;&gt;Sumo wrestling, presented by SumoLogic @ AWS re:Invent2015 Game 3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トライアル期間を利用して、さらっと触ってみた結果をメモしておきます。&lt;/p&gt;

&lt;p&gt;なお、現時点でのプランが30日トライアルのため、sumologicの全機能が利用できる状況です。30日後にフリープランになった場合、このエントリーに記載したことの何ができなくなるのか少々不安です。30日後に確認します。（参考：&lt;a href=&#34;https://www.sumologic.com/pricing/&#34;&gt;Pricing&lt;/a&gt;）&lt;/p&gt;

&lt;h2 id=&#34;sumologicにログを転送する仕組み&#34;&gt;SumoLogicにログを転送する仕組み&lt;/h2&gt;

&lt;p&gt;sumologicにログを転送する方法は2つあります。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;詳細&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;installed Collector&lt;/td&gt;
&lt;td&gt;自前のサーバ上にインストールするコレクター。サーバにエージェントが常駐する&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hosted Collector&lt;/td&gt;
&lt;td&gt;sumologic上にホストされているコレクター。サーバにエージェントをインストールする必要なし&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;詳細は&lt;a href=&#34;https://service.sumologic.com/help/Default.htm#Difference_between_Collectors.htm%3FTocPath%3DSending%2520Data%7CCollectors%7C_____1&#34;&gt;What&amp;rsquo;s the difference between Collector types?&lt;/a&gt;を参照ください。&lt;/p&gt;

&lt;p&gt;Hosted CollectorはデフォルトでAWSの以下サービスに対応しています。残念なことに、現時点でVPC Flow Logsには未対応です。（VPC Flow LogsをS3に吐き出せば、そのログを取得できるかもしれません）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;S3&lt;/li&gt;
&lt;li&gt;ELB&lt;/li&gt;
&lt;li&gt;CloudFront&lt;/li&gt;
&lt;li&gt;CloudTrail&lt;/li&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;li&gt;S3 Audit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;sumologicにvpc-flow-logsを送る方法&#34;&gt;sumologicにVPC Flow Logsを送る方法&lt;/h2&gt;

&lt;p&gt;公式のヘルプ(&lt;a href=&#34;https://service.sumologic.com/help/Default.htm#Collecting_Amazon_VPC_Flow_Logs.htm%3FTocPath%3DApps%7CSumo%2520Logic%2520App%2520for%2520Amazon%2520VPC%2520Flow%2520Logs%7C_____1&#34;&gt;Collecting Amazon VPC Flow Logs&lt;/a&gt;)に従い、installed Collectorを利用したログ転送を試したのですが、以下のエラーが出てしまい上手く行きませんでした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-01-22 17:39:29,994 10946 [pool-2-thread-4] INFO com.amazonaws.internal.DefaultServiceEndpointBuilder  - {logs, ap-southeast-1} was not found in region metadata, trying to construct an endpoint using the standard pattern for this region: &#39;logs.ap-southeast-1.amazonaws.com&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで今回は、sumologicのgithubリポジトリで公開されているLambdaファンクション（&lt;a href=&#34;https://github.com/SumoLogic/sumologic-aws-lambda/tree/master/cloudwatchlogs&#34;&gt;SumoLogic/sumologic-aws-lambda&lt;/a&gt;）を利用することにしました。このLambdaファンクションは、VPC Flow Logsに特化したものではなく、sumologicのAPIを利用してCloudWatch Logsをsumologicに送るものです。そのため、VPC Flow Logs以外でも利用可能です。&lt;/p&gt;

&lt;p&gt;なお、sumologicのAPI（Collector Management API）は、PROFESSIONALプラン以上で利用可能です。そのため、FREEプランでは利用できません。。。&lt;/p&gt;

&lt;h2 id=&#34;sumologicにログを送る&#34;&gt;sumologicにログを送る&lt;/h2&gt;

&lt;p&gt;Hosted Collectorを作成します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-002.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したHosted Collectorに、HTTPSでデータを投入できるAPIエンドポイントを追加します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-008.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-009.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-007.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-004.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したエンドポイントの情報を元に&lt;a href=&#34;https://github.com/SumoLogic/sumologic-aws-lambda/tree/master/cloudwatchlogs&#34;&gt;SumoLogic/sumologic-aws-lambda&lt;/a&gt;の内容を修正して、Lambdaファンクションを作ります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-005.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最後に、作成したLambdaファンクションをVPC Flow LogsのSubscriptionに追加します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-006.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ログを可視化する&#34;&gt;ログを可視化する&lt;/h2&gt;

&lt;p&gt;sumologicには標準でVPC Flow Logsを可視化するAppsが用意されています。とりあえずこれを利用します。FREEプランになっても使えるかは要確認です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-010.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Appには複数のダッシュボードとクエリが定義されています。とりあえずActivityなるダッシュボードを見てみます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-011.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-012.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;超カッコいい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-013.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ログを検索する&#34;&gt;ログを検索する&lt;/h2&gt;

&lt;p&gt;独自のクエリ言語を利用して、ログを検索することができます。&lt;/p&gt;

&lt;p&gt;取り込んだVPC Flow Logsを送信元IPアドレスで限定して、送信元IPアドレスと宛先IPアドレスで分類して転送バイトを合計、さらに合計値でソートしてみます。アウト方向の転送量が多い通信を特定するクエリをイメージしています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_sourceCategory=xxxx_vpcflowlogs message
| json &amp;quot;message&amp;quot;,&amp;quot;logStream&amp;quot;,&amp;quot;logGroup&amp;quot;
| parse field=message &amp;quot;* * * * * * * * * * * * * *&amp;quot; as version,accountID,interfaceID,src_ip,dest_ip,src_port,dest_port,Protocol,Packets,bytes,StartSample,EndSample,Action,status
| where src_ip = &amp;quot;172.20.0.10&amp;quot;
| sum(bytes) group by src_ip,dest_ip
| sort by _sum
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの結果が、下の方に表示されています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-014.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結果をCSVでダウンロードすることもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-015.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結果をグラフにすることもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-016.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;さらに結果をダッシュボードに追加することもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-017.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-018.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;雑な所感&#34;&gt;雑な所感&lt;/h2&gt;

&lt;p&gt;有料のSaaSだけあってかなり使いやすいです。また、Hosted Collectorを利用することで、サーバレスでAWSの各種ログを収集・分析することができます。今後、AWSのログを保存・分析するための基盤のお仕事があった場合、検討候補にしたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Amazon WorkSpacesを不便にする</title>
      <link>http://aimless.jp/blog/archives/2016-01-23-inconvenient-workspaces</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-01-23-inconvenient-workspaces</guid>
      <description>

&lt;p&gt;WorkSpacesは大変気軽です。ですが、リモートアクセス用途での導入を検討した場合、あまりにも気軽に社内LANにアクセスできてしまうことが問題となります。標準の設定のまま利用者に使わせると、社内LANに新たなリスクを生み出すことになります。&lt;/p&gt;

&lt;p&gt;もう少し不便にすることでセキュリティを高められないか、と考え、WorkSpacesのセキュリティや監査に関する機能を調査したのでメモします。
なお多要素認証については当たり前なので触れません。&lt;/p&gt;

&lt;h2 id=&#34;認証情報の記憶を無効化する&#34;&gt;認証情報の記憶を無効化する&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントは、認証情報を記憶する機能（Remember Me）があります。これを利用することで、次回以降のログインにおいてIDとパスワードの入力が不要となります。多要素認証を使っている場合、多要素認証のパスワードも記憶します。&lt;/p&gt;

&lt;p&gt;この機能は大変便利ですが、社外からのリモートアクセス用途の場合、第三者による不正利用のリスクが生まれます。この機能は利用しているDirectory Service単位で無効にすることができます。詳細は&lt;a href=&#34;http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me/&#34;&gt;Amazon WorkSpacesのRemember Me機能を使う&lt;/a&gt;を参照ください。&lt;/p&gt;

&lt;h2 id=&#34;利用状況を記録する&#34;&gt;利用状況を記録する&lt;/h2&gt;

&lt;p&gt;リモートアクセス用途の場合、有事の際に備えて、いつ誰が使っていたかをロギングできることが望ましいでしょう。&lt;/p&gt;

&lt;p&gt;AWSでロギングといえばCloudTrailですが、WorkSpacesの利用状況はCloudTrailでロギングされません。WorkSpacesクライアントがWorkSpacesに接続する際にAPI Callが行われないからです。そのかわり、CloudWatchの以下メトリックに利用状況に関するデータが保存されています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ConnectionFailure&lt;/li&gt;
&lt;li&gt;ConnectionSuccess&lt;/li&gt;
&lt;li&gt;InSessionLatency&lt;/li&gt;
&lt;li&gt;SessionDisconnect&lt;/li&gt;
&lt;li&gt;SessionLaunchTime&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CloudWatchにはWorkSpaces単位でメトリックが保存されます。原則、WorkSpacesは1ユーザ1端末ですので、いつ誰がWorkSpacesを利用したかが記録されていると言ってもいいでしょう。ただし、CloudWatchのデータは2週間しか保存されませんので、長期間の保存（例えば13か月分）が必要な場合は、APIを利用して外部のサーバにデータを記録しなけばなりません。&lt;/p&gt;

&lt;p&gt;なお、現時点で、どこから（送信元IPアドレス）と、どの端末（WorkSpacesクライアントがインストールされている環境）からを調べることはできません。実装されるとうれしいです。&lt;/p&gt;

&lt;h2 id=&#34;情報漏えいを防ぐ&#34;&gt;情報漏えいを防ぐ&lt;/h2&gt;

&lt;p&gt;デフォルトのAmazon WorkSpacesは、クリップボードのリダイレクトが有効になっています。WorkSpacesでコピーしたものを、WorkSpacesクライアントが動作するPCにペーストすることができます。リモートアクセス用途でWorkSpacesを利用している場合、技術的には、悪意あるユーザが情報を漏洩させることができます。&lt;/p&gt;

&lt;p&gt;Amazon WorkSpacesがAD ConnectorによってActive Directoryの管理下にある場合、グループポリシを利用して以下の機能を制限することができます。これにより、WorkSpaces内のデータを外部に持ち出されるリスクを極小化することができます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;クリップボードによるコピペ&lt;a href=&#34;http://docs.aws.amazon.com/workspaces/latest/adminguide/group_policy.html#gp_clipboard&#34;&gt;(Clipboard Redirection)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ローカルプリンタを利用した印刷&lt;a href=&#34;http://docs.aws.amazon.com/workspaces/latest/adminguide/group_policy.html#gp_local_printers&#34;&gt;(Local Printer Support)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;不要なセッションを積極的に切断する&#34;&gt;不要なセッションを積極的に切断する&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントは、ネットワークが切れない限りセッションを維持します。所謂アイドルタイムアウトがないようです。リモートアクセス用途の場合、使っていないのに社内LANへのアクセス口が有効になっていることはリスクです。&lt;/p&gt;

&lt;p&gt;現時点で、アイドルタイムアウトの設定は、WorkSpacesのサービス単体では実装できません。ただし、WorkSpacesがAD ConnectorによってActive Directoryの管理下にある場合、グループポリシによってアイドルタイムアウトの設定を行うことが可能です。具体的な設定は以下URLを参照ください。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/ja-jp/library/cc758177%28v=ws.10%29.aspx&#34;&gt;切断されたセッション、アクティブなセッション、およびアイドル状態のセッションに対するタイムアウト値を設定する&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;これまでの設定を実施すると、以下のようなWorkSpacesが完成します。かなり不便になりました。ですが、WorkSpacesをリモートアクセス用途で使う場合のリスクを大幅に軽減することができました。満足。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;利用するたびに、多要素認証でログインする必要がある&lt;/li&gt;
&lt;li&gt;いつ使ったか、モニタリングできる&lt;/li&gt;
&lt;li&gt;画面転送しかできない&lt;/li&gt;
&lt;li&gt;使っていないと、接続が切れる&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Amazon WorkSpacesのRemember Me機能を使う</title>
      <link>http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me</guid>
      <description>

&lt;p&gt;Amazon WorkSpacesへの憧れが止まりません。BYOD＋WorkSpacesで仕事がしたい。とはいえ、古きSIerである弊社において、いきなりBYODはレベルが高すぎます。そこで、自宅からのリモートアクセス用途として会社に対してWorkSpacesを提案することにしました。そのために色々と調べたのでメモしておきます。&lt;/p&gt;

&lt;h2 id=&#34;mfaの罠&#34;&gt;MFAの罠&lt;/h2&gt;

&lt;p&gt;AD ConnectorとRADIUSサーバによる多要素認証を使ってみて気が付いたのですが、WorkSpacesクライアントは多要素認証を使っていても認証情報を記憶します。多要素認証でログインした後に一旦切断しても、以下の画面になりボタン一つで簡単に再接続ができます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.amazonwebservices.com/blog/2015/ws_client_reconnect_2.png&#34; alt=&#34;https://media.amazonwebservices.com/blog/2015/ws_client_reconnect_2.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　認証情報を保存する機能は便利なのですが、社外に配置するPCで利用するWorkSpacesクライアントには認証情報を保存したくありません。誰が触るかわかりませんので。&lt;/p&gt;

&lt;h2 id=&#34;remember-meの無効化&#34;&gt;Remember Meの無効化&lt;/h2&gt;

&lt;p&gt;ドキュメントを調べたところ、ぴったりな機能がありました。Remember Meの無効化です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/workspaces/latest/adminguide/osx_client_help.htm&#34;&gt;Amazon WorkSpaces クライアントのヘルプ&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Amazon WorkSpaces 管理者が [Remember Me] 機能を無効にしていない場合、それ以降 WorkSpace に簡単に接続できるように、自分の認証情報を安全に保存しておくかどうかを確認するメッセージが表示されます。認証情報は、ユーザーの Kerberos チケットの最大有効期間が終了するまで安全にキャッシュに保存されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;現時点で、Remember Meの無効化はサポートにお願いする必要があります。マネジメントコンソールでは無効にできません。&lt;/p&gt;

&lt;h2 id=&#34;remember-me無効後の動作&#34;&gt;Remember Me無効後の動作&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントを切断します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-002.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-002.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;切断後の画面がRecconectになりません。IDとパスワード、ワンタイムパスワードを入力する画面に戻りました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-003.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-003.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;WorkSpacesクライアントのオプション設定でもRemember Meを有効にすることができなくなります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-004.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-004.png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;WorkSpacesはどこでもどんな端末でも使えるのが最大のメリットだと思います。ですが、どこでも使える端末に社内ネットワークにアクセスするための認証情報を保存するのはリスクがあります。Remember Meの無効化は、利便性とセキュリティを両立させる良いオプションだと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>aws2excelを作ってみた</title>
      <link>http://aimless.jp/blog/archives/2684</link>
      <pubDate>Sun, 15 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2684</guid>
      <description>

&lt;h2 id=&#34;作ったもの&#34;&gt;作ったもの&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kongou-ae/aws2excel&#34;&gt;kongou-ae/aws2excel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AWSの構成情報をxlsxファイルに書き出すスクリプトです。出力されるファイルのイメージはREADMEの画像を参照ください。勢いでやっつけているので、一部サービスにのみ対応しています。最終的にはLambdaで動かしてs3にExcelを吐き出す実装にしたい。&lt;/p&gt;

&lt;h2 id=&#34;経緯&#34;&gt;経緯&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; cloud2excel!&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660383609283457024&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; 残念ながら夢の中のお話です…&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660384559700176896&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; ごめんなさい…ごめんなさいｗ&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660384991096868865&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;自分もワクワクしながらcloud2excelを検索しまして、、、無いのであれば、勉強がてら作ってみようということで作ってみました。&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;aws-sdkを利用してAPIを叩き必要な情報を取得し、その情報をExcel に書き出しているだけです。Excelへの書き出しは&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;を使いました。&lt;/p&gt;

&lt;h2 id=&#34;雑感&#34;&gt;雑感&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;を見つけたのが今回の最大の収穫です。配列やオブジェクトの情報を、かなり簡単に表形式でExcelに書き出すことができます。さらに、&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;は、Excelからの読み込みもできるようなので、Infrastrucrture as Excelが実現できます。Excelでパラメータシートを作り、そこにパラメータを書くとAWS上にインスタンスができる。なんという黒魔術。やりませんけど。。。&lt;/p&gt;

&lt;p&gt;また、Node.jsの非同期処理に苦戦しました。async.jsを使っており期待する動作はしているものの、正しい使い方かどうか不安です。Node.js（というかJavascript）を体系的に学びたい。&lt;/p&gt;

&lt;p&gt;今後は、issueにもある通り、コードを分割してメンテナンス性を高め、ELBやRDSなどメジャーなサービスに対応しようと思います。仕事の本業はAWSではないので、プライベートで淡々とメンテしていきます。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Amazon LinuxにZabbix3.0をインストールしてハマった事</title>
      <link>http://aimless.jp/blog/archives/2682</link>
      <pubDate>Mon, 26 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2682</guid>
      <description>

&lt;p&gt;Zabbix3.0（アルファ版）のソースが公開されていたので、Amazon Linuxにインストールを試みました。その際にはまったことをメモしておきます。ハマったといっても、マニュアルのRequirementsを読んでからインストールを始めれば、全くハマらないポイントです。。。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.zabbix.com/documentation/3.0/&#34;&gt;Zabbix Documentation 3.0&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon Linuxのバージョン：2015.09&lt;/li&gt;
&lt;li&gt;Zabbixのバージョン：3.0.0 alpha3&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サポートするphpのバージョンが5-4-0以上である&#34;&gt;サポートするPHPのバージョンが5.4.0以上である&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-26-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　Amazon Linuxで何も考えずに&lt;code&gt;sudo yum install php php-gd php-bcmath php-mysql php-mbstring&lt;/code&gt;すると、インストールされるPHPのバージョンは5.3になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;============================================================================================================================
 Package                       Arch                    Version                             Repository                  Size
============================================================================================================================
Installing:
 php                           x86_64                  5.3.29-1.8.amzn1                    amzn-main                  2.8 M
 php-bcmath                    x86_64                  5.3.29-1.8.amzn1                    amzn-main                   52 k
 php-gd                        x86_64                  5.3.29-1.8.amzn1                    amzn-main                  219 k
 php-mbstring                  x86_64                  5.3.29-1.8.amzn1                    amzn-main                  2.3 M
 php-mysql                     x86_64                  5.3.29-1.8.amzn1                    amzn-main                  178 k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　Zabbix3.0は、php5.3をサポートしていません。php5.4以上をサポートしています。&lt;code&gt;sudo yum install php54 php54-gd php54-bcmath php54-mysql php54-mbstring&lt;/code&gt;でphp5.4をインストールするようにしましょう。&lt;/p&gt;

&lt;h2 id=&#34;php5-4がapache2-4系に依存している&#34;&gt;php5.4がapache2.4系に依存している&lt;/h2&gt;

&lt;p&gt;　apache2.2がインストールされている場合、php5.3をyum removeし、いざphp5.4系をyum installしようとしても、依存エラーになります。&lt;/p&gt;

&lt;p&gt;　これはphp5.4がapache2.4に依存しているためです。php5.4が必要とするapache2.4が、元々入っているapache2.2と競合してしまうためにエラーとなります。apache2.2系のパッケージを削除してからphp54のインストールを行いましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install php54 php54-gd php54-bcmath php54-mysql php54-mbstring
Loaded plugins: priorities, update-motd, upgrade-helper
Resolving Dependencies
--&amp;gt; Running transaction check
---&amp;gt; Package php54.x86_64 0:5.4.45-1.75.amzn1 will be installed
--&amp;gt; Processing Dependency: httpd-mmn = 20120211x86-64 for package: php54-5.4.45-1.75.amzn1.x86_64
--&amp;gt; Processing Dependency: php54-common(x86-64) = 5.4.45-1.75.amzn1 for package: php54-5.4.45-1.75.amzn1.x86_64
--&amp;gt; Processing Dependency: php54-cli(x86-64) = 5.4.45-1.75.amzn1 for package: php54-5.4.45-1.75.amzn1.x86_64
--&amp;gt; Processing Dependency: httpd24 for package: php54-5.4.45-1.75.amzn1.x86_64
（中略）
--&amp;gt; Finished Dependency Resolution
Error: httpd24-tools conflicts with httpd-tools-2.2.31-1.6.amzn1.x86_64
Error: httpd24 conflicts with httpd-2.2.31-1.6.amzn1.x86_64
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lambdaファンクションを雑に監視する</title>
      <link>http://aimless.jp/blog/archives/2681</link>
      <pubDate>Sun, 25 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2681</guid>
      <description>

&lt;h2 id=&#34;lambdaへの切り替え&#34;&gt;Lambdaへの切り替え&lt;/h2&gt;

&lt;p&gt;　Lambdaがスケジュール実行に対応しました。そこで、サーバレスアーキテクチャを実践すべく、conohaで動いている＠ipv6kumaの機能を、AWSに順次お引越ししています。本日時点で、以下のフルルート数とフルルートグラフのツイートはLambdaでお伝えしています。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;2015/10/25の経路数は24457だクマー。昨日と比べて35経路増えたクマ！！ /from Lambda&lt;/p&gt;&amp;mdash; ブイロクマ (@IPv6kuma) &lt;a href=&#34;https://twitter.com/IPv6kuma/status/658221773335334912&#34;&gt;2015, 10月 25&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日までの経路数をグラフにしたクマ!! &lt;a href=&#34;https://t.co/Z9jHt6yXnT&#34;&gt;https://t.co/Z9jHt6yXnT&lt;/a&gt;&lt;/p&gt;&amp;mdash; ブイロクマ (@IPv6kuma) &lt;a href=&#34;https://twitter.com/IPv6kuma/status/658221776074244097&#34;&gt;2015, 10月 25&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;lambdaを監視する&#34;&gt;Lambdaを監視する&lt;/h2&gt;

&lt;p&gt;　さて、Lambdaファンクションを書いていて気になった事があります。それは『Lambdaファンクションが正しく動作している事をどうやって監視するか』です。&lt;/p&gt;

&lt;p&gt;　現時点での＠ipv6kumaは、エラーハンドリングを書いていません。想定通りに動作した最後の箇所に&lt;code&gt;context.done()&lt;/code&gt;を記載しているだけです。したがって、エラーが起きると&lt;code&gt;context.done()&lt;/code&gt;が呼び出されないので、ログには必ず&lt;code&gt;Process exited before completing request&lt;/code&gt;が出現します。&lt;/p&gt;

&lt;p&gt;　そこで、この文言をcloudwatch logsのMetric Filterを利用して監視することで、Lambdaファンクションが想定通りに動いているかどうかを監視することにしました。&lt;/p&gt;

&lt;h2 id=&#34;設定方法&#34;&gt;設定方法&lt;/h2&gt;

&lt;p&gt;　監視したいログを選択し、&lt;code&gt;Create Metric Filter&lt;/code&gt;を選択。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-00.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　&lt;code&gt;Filter Pattern&lt;/code&gt;に&lt;code&gt;Process exited before completing request&lt;/code&gt;を入力して次に進む&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　&lt;code&gt;Metric Name&lt;/code&gt;の欄に、カスタムメトリック名を入力し&lt;code&gt;Save Filter&lt;/code&gt;を押下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　メトリックフィルターができました。このフィルターに紐づくアラームを作成します。&lt;code&gt;Create Alarm&lt;/code&gt;を押下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-03.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　必要なパラメータを入力します。Metric Filter作成時にMetricを1にしましたので、アラームの閾値は1以上とします。ActionにSNSを通知することで、エラーの発生をメールで通知します。ipv6kuma_errorのサブスクライバーは私の個人アドレスになっています。&lt;/p&gt;

&lt;p&gt;　最後に&lt;code&gt;Create Alarm&lt;/code&gt;を押下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-04.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　アラームつきのMetric Filterができました！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-05.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;動作確認&#34;&gt;動作確認&lt;/h2&gt;

&lt;p&gt;　@ipv6kumaはエラーを起こすのが大変なので、別のLambdaファンクションに同様の監視を実装して、&lt;code&gt;Process exited before completing request&lt;/code&gt;を発生させました。&lt;/p&gt;

&lt;p&gt;　少々待つと、CloudwatchのエラーがSNS経由で通知されました。これで@ipv6kumaに何かあった場合、気が付くことができます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-10-25-06.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>API Gateway &#43; Lambdaを使って、マルチクラウド管理APIを作る</title>
      <link>http://aimless.jp/blog/archives/2679</link>
      <pubDate>Sat, 18 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2679</guid>
      <description>&lt;p&gt;「単一のREST APIで複数のクラウドを操作できたら便利だろうなー」と思い調べてみたところ、以下のようなライブラリを見つけました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;言語&lt;/th&gt;
&lt;th&gt;ライブラリ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Ruby&lt;/td&gt;
&lt;td&gt;DeltaCloud&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;libcloud&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Node.js&lt;/td&gt;
&lt;td&gt;pkgcloud&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Golang&lt;/td&gt;
&lt;td&gt;Gophercloud&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;　ライブラリによってサポートするクラウドプロバイダーが異なり、さらに管理できるサービスと管理できないサービスがあります。どれか一つのライブラリと心中するのは、少々リスクだと思いました。&lt;/p&gt;

&lt;p&gt;　「何か他にいい方法はないかなー」と調べていたところに、Amazon API Gatewayがリリースされました。API Gatewayを利用すると、API Gateway経由でLambdaを実行することができます。LambdaではNode.jsとjavaが動きます。主要なクラウドにはNode.jsやjavaのSDKが存在します。つまり、API Gatewayを利用すれば、自分のやりたいことができる、マルチクラウド管理APIを作れそうな気がしました。&lt;/p&gt;

&lt;p&gt;　というわけで実践。AzureとAWSのインスタンス情報をまとめて返すAPIを作ってみます。&lt;/p&gt;

&lt;p&gt;　API Gatewayでは、/computeがGETされた場合にLambdaファンクションを発火するようにします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/07/api_gateway_setting.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　そして、対応するLambdaファンクションでは以下のコードを動かします。SDKを利用して各クラウドのインスタンス情報を取得し配列に格納し、その配列を返すスクリプトです。&lt;/p&gt;

&lt;p&gt;　とりあえずということで、認証情報の扱いは適当です。AWSの認証情報はコード内にベタ書きします。Azureの証明書は、lambdaファンクションのZIPに含めます。実際のところは、API Gatewayにアクセスする際のHTTPヘッダに認証情報を含め、Lambdaファンクションに渡す方法がカッコいいと思います。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/ad0b1366da2ee5efbbaa.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　ブラウザでAPI Gatewayの/computeにアクセスすると、以下のJSONが返ってきます。AzureとAWSのインスタンス情報が一つのJSONのレスポンスになっています。いい感じですね。このレスポンスをJavascriptでいい感じに表示するHTMLを作ってS3に配置すれば、サーバレスのマルチクラウド管理ポータルが作れるかも？&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/825a49a087311e0814ad.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/07/result_of_api.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>VPC FLow Logsを継続的にElasticSearchに投入する</title>
      <link>http://aimless.jp/blog/archives/2617</link>
      <pubDate>Sun, 14 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2617</guid>
      <description>

&lt;p&gt;VPC FLow Logsのリリース直後から、クラメソさんの「&lt;a href=&#34;http://dev.classmethod.jp/cloud/aws/vpc-flow-logs-visualized-kibana4/&#34;&gt;VPC Flow LogsをElasticsearch + Kibana4で可視化する&lt;/a&gt;」と同じことを考えていました。週末に試行錯誤した結果をアウトプットします。&lt;/p&gt;

&lt;h2 id=&#34;ログの取り方&#34;&gt;ログの取り方&lt;/h2&gt;

&lt;p&gt;　AWS SDK for Ruby を利用してClodWatch Logsを取得する方法は以下の様になります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# coding: utf-8

require &amp;#039;aws-sdk-core&amp;#039;

cloudwatchlogs = Aws::CloudWatchLogs::Client.new(region: region )

# cloudwatchlogs.get_log_eventsのオプションを定義
options = {
    log_group_name: log_group_name,
    log_stream_name: log_stream_name,
}

# ログを取得
resp = cloudwatchlogs.get_log_events(options)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　ただし、この方法でログを取得した場合、指定したlog_streamに格納されている大量のデータがレスポンスとして帰ってきます。デフォルトでは最大で1M Byte分のログが取得するようです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/sdkforruby/api/Aws/CloudWatchLogs/Client.html#get_log_events-instance_method&#34;&gt;Class: Aws::CloudWatchLogs::Client&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;By default, this operation returns as much log events as can fit in a response size of 1MB, up to 10,000 log events.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　したがって、このコードを継続的に実行すると、最初から1M byte分のログを繰り返し取得してしまいます。これでは意味がありません。実行時には、前回実行分以降のログを取得してほしい。これを実現する方法が、&lt;code&gt;get_log_events&lt;/code&gt;の&lt;code&gt;next_token&lt;/code&gt;オプションです。&lt;/p&gt;

&lt;h2 id=&#34;増分ログの取り方&#34;&gt;増分ログの取り方&lt;/h2&gt;

&lt;p&gt;　&lt;code&gt;get_log_events&lt;/code&gt;のレスポンスには&lt;code&gt;next_forward_token&lt;/code&gt;と&lt;code&gt;next_backward_token&lt;/code&gt;が含まれています。これらは取得結果の次のページの位置を示しています。より新しいログの位置は名前的に&lt;code&gt;next_forward_token&lt;/code&gt;が保持しているっぽいです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/sdkforruby/api/Aws/CloudWatchLogs/Client.html#get_log_events-instance_method&#34;&gt;Class: Aws::CloudWatchLogs::Client&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;resp.events #=&amp;gt; Array&lt;/p&gt;

&lt;p&gt;resp.events[0].timestamp #=&amp;gt; Integer&lt;/p&gt;

&lt;p&gt;resp.events[0].message #=&amp;gt; String&lt;/p&gt;

&lt;p&gt;resp.events[0].ingestion_time #=&amp;gt; Integer&lt;/p&gt;

&lt;p&gt;resp.next_forward_token #=&amp;gt; String&lt;/p&gt;

&lt;p&gt;resp.next_backward_token #=&amp;gt; String&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　そこで、このtokenを利用して&lt;code&gt;get_log_events&lt;/code&gt;を実行するように、スクリプトを変更します。tokenの値は、fluentdっぽくstateファイルを作り、そこに書き込んでおきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# coding: utf-8

require &amp;#039;aws-sdk-core&amp;#039;
require &amp;#039;fileutils&amp;#039;

region = &amp;#039;ap-northeast-1&amp;#039;
log_group_name = &amp;#039;VPCFLowLog&amp;#039;
log_stream_name = &amp;#039;eni-xxxxxxxx-all&amp;#039;
@state_file = Dir.pwd + &#34;/&#34; + log_group_name + &#34;.&#34; + log_stream_name + &#34;.state&#34;

# トークンをstateファイルに書き込む
def write_token(token)
    File.open(@state_file,&#34;w&#34;) do |file|
        file.puts(token)
    end
end

# トークンをstateファイルから読み込む
def read_token
    if File.exist?(@state_file) then
        return File.read(@state_file).chomp
    else
        return 
    end
end

cloudwatchlogs = Aws::CloudWatchLogs::Client.new(region: region )

# cloudwatchlogs.get_log_eventsのオプションを定義
options = {
    log_group_name: log_group_name,
    log_stream_name: log_stream_name,
}

# もしstateファイルから前回のtokenが取得できたら、そのtokenをオプションに追加
if read_token != nil  then
    options[:next_token] = read_token
end

# ログを取得
resp = cloudwatchlogs.get_log_events(options)

# 取得したログからtokenを保存
write_token(resp.next_forward_token)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認&#34;&gt;動作確認&lt;/h2&gt;

&lt;p&gt;　ElasticSearchに投入済みのデータは以下の通りです。19:25:47までのログが格納されています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/06/001.png&#34; alt=&#34;投入済みデータ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　&lt;code&gt;next_token&lt;/code&gt;をつけて&lt;code&gt;get_log_events&lt;/code&gt;したデータをElasticSearchに投入します。投入時のログは以下の通りです。19:28:40のデータ以降がElasticSearchに投入されていることがわかります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2015-06-14 19:38:36 +0900: &amp;gt; {&#34;@timestamp&#34;:&#34;2015-06-14 19:28:40&#34;,&#34;version&#34;:&#34;2&#34;,&#34;account-id&#34;:&#34;250369693989&#34;,&#34;interface-id&#34;:&#34;eni-f5a92c83&#34;,&#34;srcaddr&#34;:&#34;157.7.235.92&#34;,&#34;dstaddr&#34;:&#34;10.175.10.97&#34;,&#34;srcport&#34;:&#34;123&#34;,&#34;dstport&#34;:&#34;123&#34;,&#34;protocol&#34;:&#34;17&#34;,&#34;packets&#34;:&#34;1&#34;,&#34;bytes&#34;:&#34;76&#34;,&#34;start&#34;:&#34;1434277720&#34;,&#34;end&#34;:&#34;1434277760&#34;,&#34;action&#34;:&#34;ACCEPT&#34;,&#34;log-status&#34;:&#34;OK&#34;}
2015-06-14 19:38:36 +0900: &amp;lt; {&#34;_index&#34;:&#34;aws&#34;,&#34;_type&#34;:&#34;vpcflowlog&#34;,&#34;_id&#34;:&#34;AU3xpkmyyQj6bWWoL4TA&#34;,&#34;_version&#34;:1,&#34;created&#34;:true}
2015-06-14 19:38:36 +0900: POST http://localhost:9200/aws/vpcflowlog [status:201, request:0.004s, query:n/a]
2015-06-14 19:38:36 +0900: &amp;gt; {&#34;@timestamp&#34;:&#34;2015-06-14 19:28:40&#34;,&#34;version&#34;:&#34;2&#34;,&#34;account-id&#34;:&#34;250369693989&#34;,&#34;interface-id&#34;:&#34;eni-f5a92c83&#34;,&#34;srcaddr&#34;:&#34;10.175.10.97&#34;,&#34;dstaddr&#34;:&#34;157.7.235.92&#34;,&#34;srcport&#34;:&#34;123&#34;,&#34;dstport&#34;:&#34;123&#34;,&#34;protocol&#34;:&#34;17&#34;,&#34;packets&#34;:&#34;1&#34;,&#34;bytes&#34;:&#34;76&#34;,&#34;start&#34;:&#34;1434277720&#34;,&#34;end&#34;:&#34;1434277760&#34;,&#34;action&#34;:&#34;ACCEPT&#34;,&#34;log-status&#34;:&#34;OK&#34;}
2015-06-14 19:38:36 +0900: &amp;lt; {&#34;_index&#34;:&#34;aws&#34;,&#34;_type&#34;:&#34;vpcflowlog&#34;,&#34;_id&#34;:&#34;AU3xpkm4yQj6bWWoL4TB&#34;,&#34;_version&#34;:1,&#34;created&#34;:true}
2015-06-14 19:38:36 +0900: POST http://localhost:9200/aws/vpcflowlog [status:201, request:0.003s, query:n/a]
2015-06-14 19:38:36 +0900: &amp;gt; {&#34;@timestamp&#34;:&#34;2015-06-14 19:28:40&#34;,&#34;version&#34;:&#34;2&#34;,&#34;account-id&#34;:&#34;250369693989&#34;,&#34;interface-id&#34;:&#34;eni-f5a92c83&#34;,&#34;srcaddr&#34;:&#34;162.255.180.213&#34;,&#34;dstaddr&#34;:&#34;10.175.10.97&#34;,&#34;srcport&#34;:&#34;1982&#34;,&#34;dstport&#34;:&#34;445&#34;,&#34;protocol&#34;:&#34;6&#34;,&#34;packets&#34;:&#34;2&#34;,&#34;bytes&#34;:&#34;96&#34;,&#34;start&#34;:&#34;1434277720&#34;,&#34;end&#34;:&#34;1434277760&#34;,&#34;action&#34;:&#34;REJECT&#34;,&#34;log-status&#34;:&#34;OK&#34;}
2015-06-14 19:38:36 +0900: &amp;lt; {&#34;_index&#34;:&#34;aws&#34;,&#34;_type&#34;:&#34;vpcflowlog&#34;,&#34;_id&#34;:&#34;AU3xpkm9yQj6bWWoL4TC&#34;,&#34;_version&#34;:1,&#34;created&#34;:true}
2015-06-14 19:38:36 +0900: POST http://localhost:9200/aws/vpcflowlog [status:201, request:0.003s, query:n/a]
（中略）
2015-06-14 19:38:36 +0900: &amp;gt; {&#34;@timestamp&#34;:&#34;2015-06-14 19:35:22&#34;,&#34;version&#34;:&#34;2&#34;,&#34;account-id&#34;:&#34;250369693989&#34;,&#34;interface-id&#34;:&#34;eni-f5a92c83&#34;,&#34;srcaddr&#34;:&#34;10.175.10.97&#34;,&#34;dstaddr&#34;:&#34;46.17.98.184&#34;,&#34;srcport&#34;:&#34;22&#34;,&#34;dstport&#34;:&#34;27530&#34;,&#34;protocol&#34;:&#34;6&#34;,&#34;packets&#34;:&#34;1&#34;,&#34;bytes&#34;:&#34;48&#34;,&#34;start&#34;:&#34;1434278122&#34;,&#34;end&#34;:&#34;1434278181&#34;,&#34;action&#34;:&#34;ACCEPT&#34;,&#34;log-status&#34;:&#34;OK&#34;}
2015-06-14 19:38:36 +0900: &amp;lt; {&#34;_index&#34;:&#34;aws&#34;,&#34;_type&#34;:&#34;vpcflowlog&#34;,&#34;_id&#34;:&#34;AU3xpkoQyQj6bWWoL4TY&#34;,&#34;_version&#34;:1,&#34;created&#34;:true}
2015-06-14 19:38:36 +0900: POST http://localhost:9200/aws/vpcflowlog [status:201, request:0.002s, query:n/a]
2015-06-14 19:38:36 +0900: &amp;gt; {&#34;@timestamp&#34;:&#34;2015-06-14 19:36:55&#34;,&#34;version&#34;:&#34;2&#34;,&#34;account-id&#34;:&#34;250369693989&#34;,&#34;interface-id&#34;:&#34;eni-f5a92c83&#34;,&#34;srcaddr&#34;:&#34;199.203.59.117&#34;,&#34;dstaddr&#34;:&#34;10.175.10.97&#34;,&#34;srcport&#34;:&#34;26600&#34;,&#34;dstport&#34;:&#34;80&#34;,&#34;protocol&#34;:&#34;6&#34;,&#34;packets&#34;:&#34;1&#34;,&#34;bytes&#34;:&#34;48&#34;,&#34;start&#34;:&#34;1434278215&#34;,&#34;end&#34;:&#34;1434278241&#34;,&#34;action&#34;:&#34;REJECT&#34;,&#34;log-status&#34;:&#34;OK&#34;}
2015-06-14 19:38:36 +0900: &amp;lt; {&#34;_index&#34;:&#34;aws&#34;,&#34;_type&#34;:&#34;vpcflowlog&#34;,&#34;_id&#34;:&#34;AU3xpkoTyQj6bWWoL4TZ&#34;,&#34;_version&#34;:1,&#34;created&#34;:true}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　投入後のデータ一覧は以下の通りです。19:25:47以前のログが重複登録されることなく、19:25:47以降のログが増えました！！！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/06/002.png&#34; alt=&#34;投入済みデータ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　それっぽく動いたスクリプトは以下の通りです。cronで回してみてみようと思います。&lt;/p&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# coding: utf-8

require &#34;json&#34;
require &amp;#039;aws-sdk-core&amp;#039;
require &amp;#039;elasticsearch&amp;#039;
require &amp;#039;fileutils&amp;#039;

region = &amp;#039;ap-northeast-1&amp;#039;
log_group_name = &amp;#039;VPCFLowLog&amp;#039;
log_stream_name = &amp;#039;eni-xxxxxxxx-all&amp;#039;
@state_file = Dir.pwd + &#34;/&#34; + log_group_name + &#34;.&#34; + log_stream_name + &#34;.state&#34;

# トークンをstateファイルに書き込む
def write_token(token)
    File.open(@state_file,&#34;w&#34;) do |file|
        file.puts(token)
    end
end

# トークンをstateファイルから読み込む
def read_token
    if File.exist?(@state_file) then
        return File.read(@state_file).chomp
    else
        return 
    end
end

cloudwatchlogs = Aws::CloudWatchLogs::Client.new(region: region )

# cloudwatchlogs.get_log_eventsのオプションを定義
options = {
    log_group_name: log_group_name,
    log_stream_name: log_stream_name,
}

# もしstateファイルから前回のtokenが取得できたら、そのtokenをオプションに追加
if read_token != nil  then
    options[:next_token] = read_token
end

# ログを取得
resp = cloudwatchlogs.get_log_events(options)

# 取得したログからtokenを保存
write_token(resp.next_forward_token)

hash = {}
message_elements = Array.new()

message_field = [
    &#34;version&#34;,
    &#34;account-id&#34;,
    &#34;interface-id&#34;,
    &#34;srcaddr&#34;,
    &#34;dstaddr&#34;,
    &#34;srcport&#34;,
    &#34;dstport&#34;,
    &#34;protocol&#34;,
    &#34;packets&#34;,
    &#34;bytes&#34;,
    &#34;start&#34;,
    &#34;end&#34;,
    &#34;action&#34;,
    &#34;log-status&#34;]

resp.events.each {|event|

    hash[&#34;@timestamp&#34;] = Time.at(event.timestamp/1000.0).strftime(&amp;#039;%Y-%m-%d %H:%M:%S&amp;#039;)
    message_elements = event.message.split(&#34; &#34;)
    message_elements.each.with_index(0)  {|element,i|
        hash[message_field[i]] = element
    }

    # BytesとPacketsをInteger型にすると、NODATAの時の-が型エラーになるので、捨てる
    if hash[&#34;log-status&#34;] != &#34;NODATA&#34; then
        client = Elasticsearch::Client.new(hosts: &#34;localhost:9200&#34;,log: true)
        client.index(index:&#34;aws&#34;, type:&#34;vpcflowlog&#34;, body:hash.to_json)
    end
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>aws-sdk-goでELB配下のインスタンスを取得する</title>
      <link>http://aimless.jp/blog/archives/2546</link>
      <pubDate>Sat, 11 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2546</guid>
      <description>&lt;p&gt;諸事情によりAWS製ツールをインストールできないWindows端末でAWSのAPIを叩く必要があり、手法を検討しました。あーだこーだと悩んだ結果、別の端末で作成したバイナリファイルを実行することを閃きました。こんな時のためのaws-sdk-goです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &#34;fmt&#34;
    &#34;github.com/awslabs/aws-sdk-go/aws&#34;
    &#34;github.com/awslabs/aws-sdk-go/service/elb&#34;
    &#34;sort&#34;
    &#34;strings&#34;
)

func main() {
    accessKey := &#34;YOUR_ACCESS_KEY&#34;
    secretKey := &#34;YOUR_AECRET_KEY&#34;
    region := &#34;ap-northeast-1&#34;
    elbName := &#34;YOUR_ELB_NAME&#34;
    var inserviceInstances []string

    cred := aws.DetectCreds(accessKey, secretKey, &#34;&#34;)
    elbSvc := elb.New(&amp;aws.Config{Credentials: cred, Region: region})

    param := &amp;elb.DescribeInstanceHealthInput{
        LoadBalancerName: aws.String(elbName),
    }

    res, err := elbSvc.DescribeInstanceHealth(param)

    if err != nil {
        panic(err)
    }

    for i := range res.InstanceStates {
        result := *res.InstanceStates[i].InstanceID + &#34;:&#34; + *res.InstanceStates[i].State
        inserviceInstances = append(inserviceInstances, result)
    }

    sort.Strings(inserviceInstances)
    fmt.Print(strings.Join(inserviceInstances, &#34;,&#34;))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　このスクリプトを実行すると、対象ELB配下のインスタンスとその状態が表示されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;go run main.go
i-xxxxxxxx:OutOfService,i-xxxxxxxx:OutOfService
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　コンパイルしたバイナリファイルを実行しても同じ結果になります。このバイナリを問題のWindows端末で実行すれば問題は解決です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;go build main.go

&amp;gt;main.exe
i-xxxxxxxx:OutOfService,i-xxxxxxxx:OutOfService
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Terraformでセキュリティグループを管理する</title>
      <link>http://aimless.jp/blog/archives/2481</link>
      <pubDate>Sun, 22 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2481</guid>
      <description>

&lt;p&gt;Terraformによるセキュリティグループ管理に関するメモ。&lt;/p&gt;

&lt;p&gt;　Terraformのバージョンアップにより、タグ付けやegressのルールが使えるようになったので、マネジメントコンソールと同じ事ができるようになっています。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;version&lt;/th&gt;
&lt;th&gt;IMPROVEMENTS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.3.7 (February 19, 2015)&lt;/td&gt;
&lt;td&gt;provider/aws: Security group support egress rules. [GH-856]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;0.3.1 (October 21, 2014)&lt;/td&gt;
&lt;td&gt;providers/aws: Support tags for security groups.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;ファイル構成&#34;&gt;ファイル構成&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ ls                                               
var.tf　　  　terraform.tfvars        web-sg.tf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　tfファイルで利用する変数を定義するためのファイル&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$  cat var.tf                                      
variable &#34;access_key&#34; {}
variable &#34;secret_key&#34; {}
variable &#34;region&#34; {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　tfファイルで利用する変数に値を代入するためのファイル&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat terraform.tfvars 
#-------------------------------------$
# credential$
#-------------------------------------$

access_key = &#34;YOUR_ACCESS_KEY&#34;
secret_key = &#34;YOUR_SECRET_KEY&#34;

#-------------------------------------
# region
#-------------------------------------
#
region = &#34;ap-northeast-1&#34;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　実際の処理を書いたファイル。WEBサーバ向けにHTTPを全許可するセキュリティグループを作ります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat web-sg.tf 
provider &#34;aws&#34; {
    access_key = &#34;${var.access_key}&#34;
    secret_key = &#34;${var.secret_key}&#34;
    region = &#34;${var.region}&#34;
}

resource &#34;aws_security_group&#34; &#34;web-server&#34; {
  name = &#34;web-server-sg&#34;
  description = &#34;Allow traffic of webserver&#34;

  ingress {
      from_port = 80 
      to_port = 80
      protocol = &#34;tcp&#34;
      cidr_blocks = [&#34;0.0.0.0/0&#34;]
  }
  vpc_id = &#34;vpc-d01806b2&#34;
  tags {
    Name = &#34;web-server&#34;
    Made = &#34;terraform&#34;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;セキュリティグループの作成&#34;&gt;セキュリティグループの作成&lt;/h2&gt;

&lt;p&gt;まずは&lt;code&gt;terraform plan&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
Refreshing Terraform state prior to plan...


The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Note: You didn&amp;#039;t specify an &#34;-out&#34; parameter to save this plan, so when
&#34;apply&#34; is called, Terraform can&amp;#039;t guarantee this is what will execute.

+ aws_security_group.web-server
    description:                          &#34;&#34; =&amp;gt; &#34;Allow traffic of webserver&#34;
    egress.#:                             &#34;&#34; =&amp;gt; &#34;&amp;lt;computed&amp;gt;&#34;
    ingress.#:                            &#34;&#34; =&amp;gt; &#34;1&#34;
    ingress.2603706321.cidr_blocks.#:     &#34;&#34; =&amp;gt; &#34;1&#34;
    ingress.2603706321.cidr_blocks.0:     &#34;&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
    ingress.2603706321.from_port:         &#34;&#34; =&amp;gt; &#34;80&#34;
    ingress.2603706321.protocol:          &#34;&#34; =&amp;gt; &#34;tcp&#34;
    ingress.2603706321.security_groups.#: &#34;&#34; =&amp;gt; &#34;0&#34;
    ingress.2603706321.self:              &#34;&#34; =&amp;gt; &#34;0&#34;
    ingress.2603706321.to_port:           &#34;&#34; =&amp;gt; &#34;80&#34;
    name:                                 &#34;&#34; =&amp;gt; &#34;web-server-sg&#34;
    owner_id:                             &#34;&#34; =&amp;gt; &#34;&amp;lt;computed&amp;gt;&#34;
    tags.#:                               &#34;&#34; =&amp;gt; &#34;2&#34;
    tags.Made:                            &#34;&#34; =&amp;gt; &#34;terraform&#34;
    tags.Name:                            &#34;&#34; =&amp;gt; &#34;web-server&#34;
    vpc_id:                               &#34;&#34; =&amp;gt; &#34;vpc-d01806b2&#34;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　問題なさそうなので&lt;code&gt;terraform apply&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform apply
aws_security_group.web-server: Creating...
  description:                          &#34;&#34; =&amp;gt; &#34;Allow traffic of webserver&#34;
  egress.#:                             &#34;&#34; =&amp;gt; &#34;&amp;lt;computed&amp;gt;&#34;
  ingress.#:                            &#34;&#34; =&amp;gt; &#34;1&#34;
  ingress.2603706321.cidr_blocks.#:     &#34;&#34; =&amp;gt; &#34;1&#34;
  ingress.2603706321.cidr_blocks.0:     &#34;&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
  ingress.2603706321.from_port:         &#34;&#34; =&amp;gt; &#34;80&#34;
  ingress.2603706321.protocol:          &#34;&#34; =&amp;gt; &#34;tcp&#34;
  ingress.2603706321.security_groups.#: &#34;&#34; =&amp;gt; &#34;0&#34;
  ingress.2603706321.self:              &#34;&#34; =&amp;gt; &#34;0&#34;
  ingress.2603706321.to_port:           &#34;&#34; =&amp;gt; &#34;80&#34;
  name:                                 &#34;&#34; =&amp;gt; &#34;web-server-sg&#34;
  owner_id:                             &#34;&#34; =&amp;gt; &#34;&amp;lt;computed&amp;gt;&#34;
  tags.#:                               &#34;&#34; =&amp;gt; &#34;2&#34;
  tags.Made:                            &#34;&#34; =&amp;gt; &#34;terraform&#34;
  tags.Name:                            &#34;&#34; =&amp;gt; &#34;web-server&#34;
  vpc_id:                               &#34;&#34; =&amp;gt; &#34;vpc-d01806b2&#34;
aws_security_group.web-server: Creation complete

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　&lt;code&gt;1 added&lt;/code&gt;となっています。&lt;code&gt;terraform show&lt;/code&gt;で今の状態を確認します。sg-8a53d6efができました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform show                                                                         
aws_security_group.web-server:
  id = sg-8a53d6ef
  description = Allow traffic of webserver
  egress.# = 1
  egress.1965070075.cidr_blocks.# = 1
  egress.1965070075.cidr_blocks.0 = 0.0.0.0/0
  egress.1965070075.from_port = 0
  egress.1965070075.protocol = -1
  egress.1965070075.security_groups.# = 0
  egress.1965070075.self = false
  egress.1965070075.to_port = 0
  ingress.# = 1
  ingress.2603706321.cidr_blocks.# = 1
  ingress.2603706321.cidr_blocks.0 = 0.0.0.0/0
  ingress.2603706321.from_port = 80
  ingress.2603706321.protocol = tcp
  ingress.2603706321.security_groups.# = 0
  ingress.2603706321.self = false
  ingress.2603706321.to_port = 80
  name = web-server-sg
  owner_id = MY_AWS_ACCOUNT_NUMBER
  tags.# = 2
  tags.Made = terraform
  tags.Name = web-server
  vpc_id = vpc-d01806b2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　マネジメントコンソールでも、Terraformの指示通りのセキュリティグループが作成されたことが確認できます。&lt;/p&gt;

&lt;p&gt;　&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/03/2015-03-22-01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ルールの追加-inbound&#34;&gt;ルールの追加（Inbound）&lt;/h2&gt;

&lt;p&gt;　inboundにHTTPSを追加してみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat web-sg.tf 
provider &#34;aws&#34; {
    access_key = &#34;${var.access_key}&#34;
    secret_key = &#34;${var.secret_key}&#34;
    region = &#34;${var.region}&#34;
}

resource &#34;aws_security_group&#34; &#34;web-server&#34; {
  name = &#34;web-server-sg&#34;
  description = &#34;Allow traffic of webserver&#34;

  ingress {
      from_port = 80 
      to_port = 80
      protocol = &#34;tcp&#34;
      cidr_blocks = [&#34;0.0.0.0/0&#34;]
  }
  ingress {
      from_port = 443
      to_port = 443
      protocol = &#34;tcp&#34;
      cidr_blocks = [&#34;0.0.0.0/0&#34;]
  }
  vpc_id = &#34;vpc-d01806b2&#34;
  tags {
    Name = &#34;web-server&#34;
    Made = &#34;terraform&#34;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　tfファイルを編集後、&lt;code&gt;terraform plan&lt;/code&gt;からの&lt;code&gt;terraform apply&lt;/code&gt;、&lt;code&gt;terraform show&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ terraform plan
Refreshing Terraform state prior to plan...

aws_security_group.web-server: Refreshing state... (ID: sg-8a53d6ef)

The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Note: You didn&amp;#039;t specify an &#34;-out&#34; parameter to save this plan, so when
&#34;apply&#34; is called, Terraform can&amp;#039;t guarantee this is what will execute.

~ aws_security_group.web-server
    ingress.#:                            &#34;1&#34; =&amp;gt; &#34;2&#34;
    ingress.2603706321.cidr_blocks.#:     &#34;1&#34; =&amp;gt; &#34;1&#34;
    ingress.2603706321.cidr_blocks.0:     &#34;0.0.0.0/0&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
    ingress.2603706321.from_port:         &#34;80&#34; =&amp;gt; &#34;80&#34;
    ingress.2603706321.protocol:          &#34;tcp&#34; =&amp;gt; &#34;tcp&#34;
    ingress.2603706321.security_groups.#: &#34;0&#34; =&amp;gt; &#34;0&#34;
    ingress.2603706321.self:              &#34;0&#34; =&amp;gt; &#34;0&#34;
    ingress.2603706321.to_port:           &#34;80&#34; =&amp;gt; &#34;80&#34;
    ingress.4089093546.cidr_blocks.#:     &#34;0&#34; =&amp;gt; &#34;1&#34;
    ingress.4089093546.cidr_blocks.0:     &#34;&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
    ingress.4089093546.from_port:         &#34;&#34; =&amp;gt; &#34;443&#34;
    ingress.4089093546.protocol:          &#34;&#34; =&amp;gt; &#34;tcp&#34;
    ingress.4089093546.security_groups.#: &#34;0&#34; =&amp;gt; &#34;0&#34;
    ingress.4089093546.self:              &#34;&#34; =&amp;gt; &#34;0&#34;
    ingress.4089093546.to_port:           &#34;&#34; =&amp;gt; &#34;443&#34;


$ 
$ terraform apply
aws_security_group.web-server: Refreshing state... (ID: sg-8a53d6ef)
aws_security_group.web-server: Modifying...
  ingress.#:                            &#34;1&#34; =&amp;gt; &#34;2&#34;
  ingress.2603706321.cidr_blocks.#:     &#34;1&#34; =&amp;gt; &#34;1&#34;
  ingress.2603706321.cidr_blocks.0:     &#34;0.0.0.0/0&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
  ingress.2603706321.from_port:         &#34;80&#34; =&amp;gt; &#34;80&#34;
  ingress.2603706321.protocol:          &#34;tcp&#34; =&amp;gt; &#34;tcp&#34;
  ingress.2603706321.security_groups.#: &#34;0&#34; =&amp;gt; &#34;0&#34;
  ingress.2603706321.self:              &#34;0&#34; =&amp;gt; &#34;0&#34;
  ingress.2603706321.to_port:           &#34;80&#34; =&amp;gt; &#34;80&#34;
  ingress.4089093546.cidr_blocks.#:     &#34;0&#34; =&amp;gt; &#34;1&#34;
  ingress.4089093546.cidr_blocks.0:     &#34;&#34; =&amp;gt; &#34;0.0.0.0/0&#34;
  ingress.4089093546.from_port:         &#34;&#34; =&amp;gt; &#34;443&#34;
  ingress.4089093546.protocol:          &#34;&#34; =&amp;gt; &#34;tcp&#34;
  ingress.4089093546.security_groups.#: &#34;0&#34; =&amp;gt; &#34;0&#34;
  ingress.4089093546.self:              &#34;&#34; =&amp;gt; &#34;0&#34;
  ingress.4089093546.to_port:           &#34;&#34; =&amp;gt; &#34;443&#34;
aws_security_group.web-server: Modifications complete

Apply complete! Resources: 0 added, 1 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate
$ 
$ terraform show
aws_security_group.web-server:
  id = sg-8a53d6ef
  description = Allow traffic of webserver
  egress.# = 1
  egress.1965070075.cidr_blocks.# = 1
  egress.1965070075.cidr_blocks.0 = 0.0.0.0/0
  egress.1965070075.from_port = 0
  egress.1965070075.protocol = -1
  egress.1965070075.security_groups.# = 0
  egress.1965070075.self = false
  egress.1965070075.to_port = 0
  ingress.# = 2
  ingress.2603706321.cidr_blocks.# = 1
  ingress.2603706321.cidr_blocks.0 = 0.0.0.0/0
  ingress.2603706321.from_port = 80
  ingress.2603706321.protocol = tcp
  ingress.2603706321.security_groups.# = 0
  ingress.2603706321.self = false
  ingress.2603706321.to_port = 80
  ingress.4089093546.cidr_blocks.# = 1
  ingress.4089093546.cidr_blocks.0 = 0.0.0.0/0
  ingress.4089093546.from_port = 443
  ingress.4089093546.protocol = tcp
  ingress.4089093546.security_groups.# = 0
  ingress.4089093546.self = false
  ingress.4089093546.to_port = 443
  name = web-server-sg
  owner_id = MY_AWS_ACCOUNT_NUMBER
  tags.# = 2
  tags.Made = terraform
  tags.Name = web-server
  vpc_id = vpc-d01806b2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　&lt;code&gt;1 changed&lt;/code&gt;となっています。既存のリソースに変更が発生しました。マネジメントコンソール上で確認すると、inboundにHTTPSが増えています。&lt;/p&gt;

&lt;p&gt;　&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/03/2015-03-22-02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ルールの追加-outbound&#34;&gt;ルールの追加（Outbound）&lt;/h2&gt;

&lt;p&gt;　新たにサポートされたegressも使ってみます。sg-2da11148がNATインスタンスに適用されている体で、sg-2da11148向けのOutbound全通信を許可するルールを追加します。&lt;/p&gt;

&lt;p&gt;　許可対象にセキュリティグループを利用する時は、&lt;code&gt;cidr_blocks&lt;/code&gt;ではなく&lt;code&gt;security_groups&lt;/code&gt;を利用します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat web-sg.tf 
provider &#34;aws&#34; {
    access_key = &#34;${var.access_key}&#34;
    secret_key = &#34;${var.secret_key}&#34;
    region = &#34;${var.region}&#34;
}

resource &#34;aws_security_group&#34; &#34;web-server&#34; {
  name = &#34;web-server-sg&#34;
  description = &#34;Allow traffic of webserver&#34;

  ingress {
      from_port = 80 
      to_port = 80
      protocol = &#34;tcp&#34;
      cidr_blocks = [&#34;0.0.0.0/0&#34;]
  }
  ingress {
      from_port = 443
      to_port = 443
      protocol = &#34;tcp&#34;
      cidr_blocks = [&#34;0.0.0.0/0&#34;]
  }
  egress {
      from_port = 0
      to_port = 65535
      protocol = &#34;-1&#34;
      security_groups = [&#34;sg-2da11148&#34;]
  }
  vpc_id = &#34;vpc-d01806b2&#34;
  tags {
    Name = &#34;web-server&#34;
    Made = &#34;terraform&#34;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　tfファイルを編集後、&lt;code&gt;terraform plan&lt;/code&gt;からの&lt;code&gt;terraform apply&lt;/code&gt;、&lt;code&gt;terraform show&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$  terraform plan
Refreshing Terraform state prior to plan...

aws_security_group.web-server: Refreshing state... (ID: sg-8a53d6ef)

The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Note: You didn&amp;#039;t specify an &#34;-out&#34; parameter to save this plan, so when
&#34;apply&#34; is called, Terraform can&amp;#039;t guarantee this is what will execute.

~ aws_security_group.web-server
    egress.2221449193.cidr_blocks.#:              &#34;0&#34; =&amp;gt; &#34;0&#34;
    egress.2221449193.from_port:                  &#34;&#34; =&amp;gt; &#34;0&#34;
    egress.2221449193.protocol:                   &#34;&#34; =&amp;gt; &#34;-1&#34;
    egress.2221449193.security_groups.#:          &#34;0&#34; =&amp;gt; &#34;1&#34;
    egress.2221449193.security_groups.1429001686: &#34;&#34; =&amp;gt; &#34;sg-2da11148&#34;
    egress.2221449193.self:                       &#34;&#34; =&amp;gt; &#34;0&#34;
    egress.2221449193.to_port:                    &#34;&#34; =&amp;gt; &#34;65535&#34;


$ terraform apply
aws_security_group.web-server: Refreshing state... (ID: sg-8a53d6ef)
aws_security_group.web-server: Modifying...
  egress.2221449193.cidr_blocks.#:              &#34;0&#34; =&amp;gt; &#34;0&#34;
  egress.2221449193.from_port:                  &#34;&#34; =&amp;gt; &#34;0&#34;
  egress.2221449193.protocol:                   &#34;&#34; =&amp;gt; &#34;-1&#34;
  egress.2221449193.security_groups.#:          &#34;0&#34; =&amp;gt; &#34;1&#34;
  egress.2221449193.security_groups.1429001686: &#34;&#34; =&amp;gt; &#34;sg-2da11148&#34;
  egress.2221449193.self:                       &#34;&#34; =&amp;gt; &#34;0&#34;
  egress.2221449193.to_port:                    &#34;&#34; =&amp;gt; &#34;65535&#34;
aws_security_group.web-server: Modifications complete

Apply complete! Resources: 0 added, 1 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate
$ terraform show
aws_security_group.web-server:
  id = sg-8a53d6ef
  description = Allow traffic of webserver
  egress.# = 1
  egress.2221449193.cidr_blocks.# = 0
  egress.2221449193.from_port = 0
  egress.2221449193.protocol = -1
  egress.2221449193.security_groups.# = 1
  egress.2221449193.security_groups.1429001686 = sg-2da11148
  egress.2221449193.self = false
  egress.2221449193.to_port = 65535
  ingress.# = 2
  ingress.2603706321.cidr_blocks.# = 1
  ingress.2603706321.cidr_blocks.0 = 0.0.0.0/0
  ingress.2603706321.from_port = 80
  ingress.2603706321.protocol = tcp
  ingress.2603706321.security_groups.# = 0
  ingress.2603706321.self = false
  ingress.2603706321.to_port = 80
  ingress.4089093546.cidr_blocks.# = 1
  ingress.4089093546.cidr_blocks.0 = 0.0.0.0/0
  ingress.4089093546.from_port = 443
  ingress.4089093546.protocol = tcp
  ingress.4089093546.security_groups.# = 0
  ingress.4089093546.self = false
  ingress.4089093546.to_port = 443
  name = web-server-sg
  owner_id = MY_AWS_ACCOUNT_NUMBER
  tags.# = 2
  tags.Made = terraform
  tags.Name = web-server
  vpc_id = vpc-d01806b2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　1 changed　となっています。既存のリソースに変更が発生しています。マネジメントコンソール上で確認すると、outboundにsg-2da11148向けのALL Trafficが増えています。&lt;/p&gt;

&lt;p&gt;　&lt;img src=&#34;http://aimless.jp/blog/wp-content/uploads/2015/03/2015-03-22-03.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terraformのroot_block_deviceを使う</title>
      <link>http://aimless.jp/blog/archives/2439</link>
      <pubDate>Mon, 09 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2439</guid>
      <description>

&lt;p&gt;Terraformのroot_block_deviceで躓いたのでメモ。&lt;/p&gt;

&lt;h2 id=&#34;やりたいこと&#34;&gt;やりたいこと&lt;/h2&gt;

&lt;p&gt;　Terraformを利用して、10Gのルートデバイスと20Gのブロックデバイスを持ったt2.microのインスタンスを起動する&lt;/p&gt;

&lt;h2 id=&#34;やったこと&#34;&gt;やったこと&lt;/h2&gt;

&lt;p&gt;　クレデンシャルを記載したtfファイルを作成する&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/a993635d9521162fe6b4.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　リソース作成の処理を記載したtfファイルを作成する&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/ccb5844778b3d1880f11.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　処理で利用する変数ファイルをまとめて定義するtfファイルを作成する&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/effeb26ef16f22c18386.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　terraform実行時に渡す変数をまとめたtfファイルを作成する&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/4bbc36de4c64ea1c4fe0.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　terraformする。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/4b8f40fe3a91b6a288c1.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;失敗談&#34;&gt;失敗談&lt;/h2&gt;

&lt;p&gt;　ebs_root_device_nameの値をAMIのルートデバイス名と異なる値にしたところ、root_block_deviceのパラメータが追加のブロックデバイスとして判断されてしまった。&lt;/p&gt;

&lt;p&gt;　たとえば、Amazon Linuxに対してebs_root_device_nameを指定しないと、デフォルト値である/dev/sda1が利用されてしまい、ルートデバイスはAMIのデフォルト、そのほかにブロックデバイスが追加で2個EBSが作成されてしまう。&lt;/p&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;h3 id=&#34;失敗の事例&#34;&gt;失敗の事例&lt;/h3&gt;

&lt;p&gt;　ebs_root_device_nameを指定せずにterraformしたログは以下の通り。terraform plan ではルートデバイス1個、ブロックデバイス1個となっているが、terraform applyしてみると、block_device.# = 2になっている。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/7ae35971fa5a2c8a17e0.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>業務時間外にEC2を停止する</title>
      <link>http://aimless.jp/blog/archives/2429</link>
      <pubDate>Thu, 26 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2429</guid>
      <description>&lt;p&gt;AWS上に複数人が利用する開発用サーバを立てました。24時間365日稼働させる必要はありませんが、手作業で起動・停止を行うのも馬鹿げています。&lt;/p&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;p&gt;　そこで、業務時間外に対象インスタンスを停止し、始業前に対象インスタンスを開始するスクリプトを書いて、NATインスタンス上のcronで実行してみました。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/kongou-ae/039ef45a992393e00418.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;　ちゃんと動いていますが、以下の様な点を修正する必要がありますね。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AWS CLIの実行結果が標準出力となり、ec2-userにメールが届いてしまう&lt;/li&gt;
&lt;li&gt;万が一起動に失敗した場合、他のメンバーに迷惑がかかるので、メール通知したい。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>