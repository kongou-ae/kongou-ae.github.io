<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Aimless</title>
    <link>http://aimless.jp/blog/</link>
    <description>Recent content in Blogs on Aimless</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 11 Jun 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://aimless.jp/blog/feed/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>airinterop.jpを支える技術</title>
      <link>http://aimless.jp/blog/archives/2016-06-11-the-technology-to-support-airinterop</link>
      <pubDate>Sat, 11 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-06-11-the-technology-to-support-airinterop</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;2年前から、「airinterop.jp」という非公認ネタサイトを作っています。簡単なウェブサイトくらい気軽に建てられるくらいのスキルは欲しいので。&lt;/p&gt;

&lt;p&gt;例年は、適当にHTMLとCSSを作りVPS上のApacheで公開するだけでした。ですが、今年のairinterop.jpは、製作者のスキル向上に伴い、新しい取り組みを行いました。来年のためにもやったことをメモしておきます&lt;/p&gt;

&lt;h2 id=&#34;webページ公開&#34;&gt;WEBページ公開&lt;/h2&gt;

&lt;p&gt;今年のairinterop.jpは、S3の静的ウェブサイトホスティングを利用しました。&lt;/p&gt;

&lt;p&gt;去年までのairInterop.jpはConoHaで稼働していました。ですが、経費節約を目的にConoHaを解約したため、Apacheやnginxに頼ることができません。現時点で常時稼働しているVPSは、リモート艦これ用のさくらのVPS for Windows Serverだけです。ですが、このVPSは、艦これのせいでCPUが常時90%を超えているため、サービスを公開するのに不向きです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ネタサイトのために再びVPSを借りるのは馬鹿らしいので、S3の静的ウェブサイトホスティングでリリースしました&lt;/p&gt;

&lt;h2 id=&#34;参加者カウンタ&#34;&gt;参加者カウンタ&lt;/h2&gt;

&lt;p&gt;「airinterop.jpの参加者が可視化されたら面白くね？」という思いつきから、Doorkeeperなどのイベント登録サイトのように、参加者のTwitterアイコンを表示するようにしました。公式サイトも来場者数を公表していますし。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;静的ウェブサイトホスティングにしてしまったので、サーバ側でTwitterアイコンを動的に描画することはできません。そこで、API Gateway＋mithril.jsを使って、クライアント側で動的に描画することにしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-04.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;API Gatewayが返すデータはMockを使いました。DynamoDBやLambdaからデータを返すよりも安上がりで実装も簡単です。Lambdaを利用して#airinteropのハッシュタグをツイートした人のデータを作成し、そのデータを使ってAPI GatewayのMock を更新しました。&lt;/p&gt;

&lt;p&gt;初めてaws-sdkでAPI Gatewayを操作したので、updateIntegrationResponseしたあとにcreateDeploymentすることに気が付くのに時間がかかりました。その結果、Mockのデータは更新されているのにAPI Gatewayが返すデータが古いままという事象に数時間悩みました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;function(body,callback){
  var apigateway = new AWS.APIGateway();
  var params = {
    httpMethod: &#39;GET&#39;, /* required */
    resourceId: &#39;xxxxxxxxxx&#39;, /* required */
    restApiId: &#39;xxxxxxxxxx&#39;, /* required */
    statusCode: &#39;200&#39;, /* required */
    patchOperations: [
      {
        op: &#39;replace&#39;,
        path: &#39;/responseTemplates/application~1json;charset=UTF-8&#39;,
        value: JSON.stringify(body)
      }
    ]
  };
  apigateway.updateIntegrationResponse(params, function(err, data) {
    var params = {
      restApiId: &#39;xxxxxxxxxx&#39;, /* required */
      stageName: &#39;prod&#39;, /* required */
    }
    apigateway.createDeployment(params, function(err, data) {
      if (err) {
        console.log(err, err.stack);
      } else {
        callback()  
      }
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mithril.jsは以下のような簡単なコードです。API Gatewayから取得したjsonをデータバインディング用の配列に格納し格納し、Viewでその配列を描画します。なお、いまだにControllerとView Model、Modelの使い分けがわかりません。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var register = {}

register.vm = {
    init: function(){
    
        register.vm.listAry = m.prop([])
        m.request({
            Method:&amp;quot;GET&amp;quot;,
            url:&amp;quot;https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod&amp;quot;,
        }).then(function(responce){
            for (var i = 0; i&amp;lt; responce.length; i++){
                register.vm.listAry().push(responce[i])
            }
        });
    }        
};

register.controller = function () {
    register.vm.init()
}

register.view = function(){
    return [
        m(&amp;quot;h2&amp;quot;,register.vm.listAry().length + &#39;人の参加者&#39;),
        register.vm.listAry().map(function(data){
            return [
                m(&amp;quot;div&amp;quot;,{class:&amp;quot;resister-icon&amp;quot;},[
                    m(&amp;quot;img&amp;quot;,{src:data.profile_image_url})
                ])
            ]
        })        
    ]
}

m.mount(document.getElementById(&amp;quot;twit-register&amp;quot;), {
  controller: register.controller,
  view: register.view
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参加者の情報は自動で定期更新されるべきですので、Cloudwatch Eventsを使って、MOCKのデータ更新用Lambdaを定期発火しました。lambdaの定期実行は、Lambda側で設定することもできますが、Cloudwatch Eventsを使ったほうがcrontabのように一覧性が高くなるので好きです。&lt;/p&gt;

&lt;h2 id=&#34;airinteopのツイート分析&#34;&gt;#airinteopのツイート分析&lt;/h2&gt;

&lt;p&gt;会期中、本家のBest of show awardsのようなことをやりたくなりました。そこで、Twitter APを使って#airinteropのツイートを収集し、最もリツイート数の多いツイートを、勝手にBest of Airinterop Awardとして表彰しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-06-11-03.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;手作業で集計するのは非常に大変なので、node.jsとtwitを使って集計スクリプトを作りこみました。とりあえず集計優先で動くコードを書きましたが、next_resultsがなくなるまで検索を続ける処理について、もう少し良いアルゴリズムがありそうな気がします。&lt;/p&gt;

&lt;p&gt;以下のスクリプトを動かすと、Retweet数トップ5のツイートを埋め込むためのHTMLコード
を取得することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var Twit = require(&#39;twit&#39;);
var async = require(&#39;async&#39;);

var T = new Twit({
});

var loop = 20
var loopAry = []
for (var k = 0; k&amp;lt;loop; k++){
  loopAry.push(k)
}
  
var regex = new RegExp(/max_id=(.+)&amp;amp;q=/)
var max_id = &amp;quot;&amp;quot;
var body = []
var param = { 
  q: &#39;#airinterop&#39;, 
  count:100
}

async.eachSeries(loopAry,
  function(item,callback){  
    if (max_id != &amp;quot;&amp;quot;){
      param.max_id = max_id
    } 
       
    T.get(&#39;search/tweets&#39;, param, function(err, data){
      var statuses = data[&#39;statuses&#39;];
      for (var i = 0; i &amp;lt; statuses.length ; i++) {
        // retweetは除く
        if(!statuses[i].retweeted_status){
          var obj = {};
          obj.created_at = statuses[i].created_at;
          obj.screen_name = statuses[i].user.screen_name
          obj.id_str = statuses[i].id_str
          obj.retweet_count = statuses[i].retweet_count;
          obj.text = statuses[i].text;
          body.push(obj)                        
        }
      };
      if (data.search_metadata.next_results){
        max_id = data.search_metadata.next_results.match(regex)[1]          
        callback();
      } else {
        var fakeErr = new Error();
        fakeErr.break = true;
        return callback(fakeErr);
      }
    })    
  },
  function(err){
    body.sort(function(a,b){
      if(a.retweet_count &amp;lt; b.retweet_count ) return 1;
        if(a.retweet_count &amp;gt; b.retweet_count ) return -1;
        return 0
    })
      
    var awards = []
    for (var j = 0; j &amp;lt; 5;j++){
      awards.push(body[j])
    }
      
    var paramOembed ={}
    
    async.eachSeries(awards,function(item,callback){
      paramOembed = {
        id:item.id_str
      }
                
      T.get(&#39;statuses/oembed&#39;, paramOembed, function(err, data){
        console.log(data)
        callback()
      })
    })
  }
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;来年への意気込み&#34;&gt;来年への意気込み&lt;/h2&gt;

&lt;p&gt;来年は何をしましょうか。やりきってしまった感があります。公式サイトを眺めてもネタが思いつきませんので、独自路線に進むしかありません。BOTが流行っているので、えあーいんたろっぷん的な、皆様がつぶやいた面白展示をご案内するBOTを作ってみたいですね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pandocの力を借りて、RedPenでWordファイルをテストする</title>
      <link>http://aimless.jp/blog/archives/2016-05-01-testing-docx-by-pandoc-and-redpen</link>
      <pubDate>Sun, 01 May 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-05-01-testing-docx-by-pandoc-and-redpen</guid>
      <description>

&lt;h2 id=&#34;経緯&#34;&gt;経緯&lt;/h2&gt;

&lt;p&gt;textlintとRedPenのどちらを使うかを悩み、「会社で使うWindowsのPCにインストールしやすいから」という理由でRedPenを選んでから、数か月がたちました。そんな中、昨日、自分の頭の中に神が降りてきました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;RedPenがWordに対応していなくて困ったが、PandocをかませてWordをmarkdownにすればいいだけだった。&lt;/p&gt;&amp;mdash; こんごー@頑張らないために頑張る (@kongou_ae) &lt;a href=&#34;https://twitter.com/kongou_ae/status/725997053277409281&#34;&gt;2016年4月29日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;RedPenはWordファイルに対応していません。ですが、Pandocを使ってWordファイルをMarkdownに変換すれば、RedPenでWordファイルの内容をテストできます。なぜ今まで思いつかなかった。&lt;/p&gt;

&lt;h2 id=&#34;実践&#34;&gt;実践&lt;/h2&gt;

&lt;p&gt;Pandocはインストーラを使ってインストールします。RedPenはGitHubで配布されている圧縮ファイルをCドライブ直下に展開します。&lt;/p&gt;

&lt;p&gt;PandocとRedPenをそれぞれコマンドラインで実行するのは大変なので、一連の処理をバッチにまとめます。バッチに渡したファイルの拡張子が&lt;code&gt;.docx&lt;/code&gt;であったら、Pandocを使って中間ファイル&lt;code&gt;tmp.md&lt;/code&gt;に変換したうえでRedPenによる検査を実施します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@echo off
set PANDOCROOT=C:\Users\xxxxxx\AppData\Local\Pandoc
set REDPENROOT=C:\redpen-distribution-1.5.2
set PROJECTROOT=%~dp0
set FILENAME=%1
set FILETYPE=%~x1

IF &amp;quot;%1&amp;quot; EQU &amp;quot;&amp;quot; (
  echo ファイルを指定してください
  exit 1
)

IF %FILETYPE% EQU .docx (
  rem convert word to markdown
  cd %PROJECTROOT%
  %PANDOCROOT%\pandoc.exe -f docx -t markdown %FILENAME% -o tmp\tmp.md

  rem test by redpen
  %REDPENROOT%\bin\redpen -c %REDPENROOT%\conf\redpen-conf-ja-new.xml %PROJECTROOT%\tmp\tmp.md
  del tmp\tmp.md
  exit 0
) ELSE IF %FILETYPE% EQU .md (
  rem test by redpen
  %REDPENROOT%\bin\redpen -c %REDPENROOT%\conf\redpen-conf-ja-new.xml %PROJECTROOT%\%FILENAME%
  exit 0
) ELSE (
  echo .docxか.mdのファイルを引数に指定してください。
  exit 1
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;バッチファイルを使ってWordファイルをテストしてみます。RedPenによる検査が実施され、エラーを検出しています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\pandoc-redpen&amp;gt; .\test.bat .\test.docx
[2016-05-01 20:13:33.382][INFO ] cc.redpen.Main - Configuration file: C:\redpen-distribution-1.5.2\conf\redpen-conf-ja-new.xml
[2016-05-01 20:13:33.417][INFO ] cc.redpen.config.ConfigurationLoader - Loading config from specified config file: &amp;quot;C:\redpen-distribution-1.5.2\conf\redpen-conf-ja-new.xml&amp;quot;
[2016-05-01 20:13:33.466][INFO ] cc.redpen.config.ConfigurationLoader - Succeeded to load configuration file
[2016-05-01 20:13:33.468][INFO ] cc.redpen.config.ConfigurationLoader - Language is set to &amp;quot;ja&amp;quot;
[2016-05-01 20:13:33.472][WARN ] cc.redpen.config.ConfigurationLoader - No variant configuration...
[2016-05-01 20:13:33.480][INFO ] cc.redpen.config.ConfigurationLoader - No &amp;quot;symbols&amp;quot; block found in the configuration
[2016-05-01 20:13:33.503][INFO ] cc.redpen.config.SymbolTable - &amp;quot;ja&amp;quot; is specified.
[2016-05-01 20:13:33.507][INFO ] cc.redpen.config.SymbolTable - &amp;quot;zenkaku&amp;quot; variant is specified
[2016-05-01 20:13:35.883][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[。, ？, ！]&amp;quot; are added as a end of sentence characters
[2016-05-01 20:13:35.886][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[’, ”]&amp;quot; are added as a right quotation characters
[2016-05-01 20:13:36.165][INFO ] cc.redpen.validator.JavaScriptValidator - JavaScript validators directory: js
tmp.md:0: ValidationError[ParagraphNumber], セクション内のパラグラフ数が最大の&amp;quot;46&amp;quot;を超えています at line:
tmp.md:1: ValidationError[JavaScript], [termsValidator0.js] 文書規約違反(MyCompany)です。「事」を修正してください。（正：こと　誤：事） at line: ごはんの事である。
tmp.md:1: ValidationError[JavaScript], [jtfStyleGuideValidator.js] 文書規約違反(JTF-2.2.1)です。「何時」を修正してください。（正：いつ　誤：何時） at line: 何時かご飯を食べて下さい。
（中略）
[2016-05-01 20:13:41.233][ERROR] cc.redpen.Main - The number of errors &amp;quot;45&amp;quot; is larger than specified (limit is &amp;quot;1&amp;quot;).
PS C:\pandoc-redpen&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;Pandocを利用することで、RedPenが対応していないフォーマットのドキュメントを検査することができました。&lt;/p&gt;

&lt;p&gt;最近対応したプロジェクトでは、「Excelに定義されている文書規約に沿って提案書を書き、レビューではその文書規約どおりであることを手作業で確認する」という地獄を体験しました。この無意味な地獄をPandocとRedPenの合わせ技で乗り切れるように仕込みをしようと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CircleCIのテストをスキップする</title>
      <link>http://aimless.jp/blog/archives/2016-04-25-skipping-test-by-circleci</link>
      <pubDate>Mon, 25 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-04-25-skipping-test-by-circleci</guid>
      <description>

&lt;h2 id=&#34;テストをスキップしたい時もある&#34;&gt;テストをスキップしたい時もある&lt;/h2&gt;

&lt;p&gt;下図のようなデプロイメントプロセスでブログを書いています。CircleCIを中心としたプロセスで、それなりに便利なのですが、ブログを公開するためにはRedPenのテストに合格しなければなりません。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-04-25-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;RedPenのJavaScript拡張を利用したスペルチェックのロジックがイマイチなのか、前回のエントリ作成時に「Email」を「Gmail」や「Emacs」のスペルミスと判定する悲劇が起きました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-04-18-sending-zabbix-alert-mail-by-gmail.md:17: ValidationError[JavaScript], [spellCheck.js] Emailはスペルミスの可能性があります。Emacsではありませんか？ at line: 管理＞メディアタイプ＞Emailから以下の通り設定します。
2016-04-18-sending-zabbix-alert-mail-by-gmail.md:17: ValidationError[JavaScript], [spellCheck.js] Emailはスペルミスの可能性があります。Gmailではありませんか？ at line: 管理＞メディアタイプ＞Emailから以下の通り設定します。

[2016-04-18 23:50:47.809][ERROR] cc.redpen.Main - The number of errors &amp;quot;2&amp;quot; is larger than specified (limit is &amp;quot;1&amp;quot;).

bash ./test-redpen.sh returned exit code 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;本来はテストを直すべきなのですが、「テストをスキップしたいことがあるだろう」ということで、任意のコミットについてCircleCIでのテストをスキップする仕組みを実装しました。&lt;/p&gt;

&lt;h2 id=&#34;circleci標準のスキップ機能&#34;&gt;CircleCI標準のスキップ機能&lt;/h2&gt;

&lt;p&gt;CircleCIに標準実装されている機能は&lt;code&gt;[skip ci]&lt;/code&gt;です。コミットログに&lt;code&gt;[skip ci]&lt;/code&gt;を含めるとCircleCIによる処理が行われません。&lt;/p&gt;

&lt;p&gt;私の場合、③テストだけをスキップしたいので、&lt;code&gt;[skip ci]&lt;/code&gt;はやりすぎです。CircleCIによる処理が行われない場合、HUGOによるビルトやGitHub Pagesへの公開がなされないためです。&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;そこでテスト実行のスクリプトに、コミットメッセージに応じた条件分岐を追加することにしました。&lt;/p&gt;

&lt;p&gt;直近のコミットメッセージは&lt;code&gt;git log -n 1 --oneline --pretty=format:&amp;quot;%s&amp;quot;&lt;/code&gt;で取得できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PS C:\Hugo\aimless.jp&amp;gt; git log -n 1 --oneline
bbe9a63 add image
PS C:\Hugo\aimless.jp&amp;gt; git log -n 1 --oneline --pretty=format:&amp;quot;%s&amp;quot;
add image
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このコマンドの結果を利用してテスト実行のスクリプトを分岐させることで、コミットメッセージに応じてテストがスキップされるようにします。テスト実行のスクリプトを以下のようにすると、コミットメッセージに&lt;code&gt;[skip test]&lt;/code&gt;が含まれている場合、RedPenによるテストが実行されません。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
mv redpen/blog.xml redpen-*/conf
mv redpen/*.js redpen-*/js


filename=`git diff HEAD^ HEAD --name-only`

commitMassage=`git log -n 1 --oneline --pretty=format:&amp;quot;%s&amp;quot;`

if [[ $filename =~ .*\.md$ ]] ;then
    if [[ &amp;quot;$commitMassage&amp;quot; =~ \[&amp;quot;skip test&amp;quot;\] ]]; then
        echo &amp;quot;redpen test is skipped.&amp;quot;
    else
        echo &amp;quot;start to test $filename....&amp;quot;
        redpen-*/bin/redpen -c redpen-*/conf/blog.xml -f markdown $filename
    fi
else
    echo &amp;quot;$filename is not markdown. Redpen test is skipped.&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;動作確認&#34;&gt;動作確認&lt;/h2&gt;

&lt;p&gt;コミットメッセージを「update」とすると、CircleCIによってRedPenのテストが実行されます。ひらがなにしたほうが読みやすい表現に関するエラーがでています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-04-25-002.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;コミットメッセージを「update [skip test]」とすると、CircleCIによるRedPenのテストは実行されません。そのかわりに、スクリプトで設定した&lt;code&gt;redpen test is skipped.&lt;/code&gt;が表示されます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-04-25-003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;任意のコミットメッセージによって、CircleCIが実行するテスト用スクリプトを分岐させてみました。CIツールが実行する処理を、個々のコマンドを実行する形ではなく、個々のコマンドをまとめたスクリプトを実行する形にすると、コミットメッセージに応じてCIツールのテストの処理を分岐させることができます。これはテストに限らず、いろいろなシーンで活用できそうです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gmailを使ってZabbix3.0のアラートメールを送る</title>
      <link>http://aimless.jp/blog/archives/2016-04-18-sending-zabbix-alert-mail-by-gmail</link>
      <pubDate>Mon, 18 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-04-18-sending-zabbix-alert-mail-by-gmail</guid>
      <description>

&lt;p&gt;Zabbix3.0からメールの暗号化方式にSTARTTLSとSSL/TLSが選択できるようになったようです。（&lt;a href=&#34;https://www.zabbix.com/documentation/3.0/manual/config/notifications/media/email&#34;&gt;参考：1 E-mail&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;というわけで、GmailのSMTPサーバを使ってアラートメールを送信してみました。SMTP heloは適当です。&lt;/p&gt;

&lt;h3 id=&#34;設定&#34;&gt;設定&lt;/h3&gt;

&lt;p&gt;管理＞メディアタイプから以下の通り設定します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-04-18-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;動作確認&#34;&gt;動作確認&lt;/h3&gt;

&lt;p&gt;無事メールが届きました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-04-18-002.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>asciidoctor-pdfでそれっぽい表紙を作る</title>
      <link>http://aimless.jp/blog/archives/2016-02-16-titlepage-of-pdffile-created-by-asciidoctorpdf</link>
      <pubDate>Tue, 16 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-16-titlepage-of-pdffile-created-by-asciidoctorpdf</guid>
      <description>

&lt;h2 id=&#34;デフォルトの表紙&#34;&gt;デフォルトの表紙&lt;/h2&gt;

&lt;p&gt;asciidoctor-pdfでは、H1と以下2行をもとに表紙が生成されます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;= ウルトラスペシャル ハイパーギガンティックサービス サービス仕様書: ミラクルマジカル編
ほげほげ株式会社 &amp;lt;doc.writer@example.jp&amp;gt;
v1.0, 2014-01-01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テーマをカスタマイズせずにPDFを生成すると、以下のような形になります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-02-16-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;テーマファイルを使って表紙をカスタマイズする&#34;&gt;テーマファイルを使って表紙をカスタマイズする&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/asciidoctor/asciidoctor-pdf/blob/master/docs/theming-guide.adoc#title-page&#34;&gt;テーマファイルのコンフィグ例&lt;/a&gt;をもとに、表紙をカスタマイズしてみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;title_page:
  align: center
  title_top: 40%
  title_font_size: $heading_h1_font_size
  title_font_color: 000000
  title_line_height: 0.9
  subtitle_font_size: $heading_h3_font_size
  subtitle_line_height: 3
  authors_margin_top: $base_font_size * 3
  authors_font_size: $base_font_size_large
  authors_font_color: 181818
  revision_margin_top: $base_font_size * 3
  logo_image: image:889.png[scaledwidth=25%]
  logo_top: 75%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;かっこよくなりました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-02-16-002.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;タイトルの改行位置を調整する&#34;&gt;タイトルの改行位置を調整する&lt;/h2&gt;

&lt;p&gt;タイトルが変な位置で改行されてしまっているので修正します。H1の文字列をで区切ることで、PDFのタイトルを任意の位置で改行することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; = ウルトラスペシャル ハイパーギガンティック エターナルフォースサービス サービス仕様書: ミラクルマジカル編
ほげほげ株式会社 &amp;lt;doc.writer@example.jp&amp;gt;
v1.0, 2014-01-01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-02-16-003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;狙った位置でタイトルが改行されました。可読性を向上させることができました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Apache Drill を使ってVPC Flow Logsを集計する</title>
      <link>http://aimless.jp/blog/archives/2016-02-14-analysing-vpcflowlogs-by-apachedrill</link>
      <pubDate>Sun, 14 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-14-analysing-vpcflowlogs-by-apachedrill</guid>
      <description>

&lt;h2 id=&#34;vpc-flow-logsを集計する&#34;&gt;VPC FLow Logsを集計する&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader/&#34;&gt;flowlogs-readerを使って、VPC Flow Logsをコマンドラインで操作する&lt;/a&gt;にて、flowlogs-readerの標準出力をawkで集計する方法を紹介しました。&lt;/p&gt;

&lt;p&gt;ですが、この方法は自分が意図するシェル芸を考えることが大変です。もう少しスマートなやり方はないものかと考えた結果、Apache Drillを使う方法を思いついたので試してみました。&lt;/p&gt;

&lt;h2 id=&#34;apache-drillのインストール&#34;&gt;Apache Drillのインストール&lt;/h2&gt;

&lt;p&gt;とりあえず使うことを目的としますので、tar.gzをダウンロードして解凍するだけにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget http://ftp.jaist.ac.jp/pub/Apache/drill/drill-1.4.0/Apache-drill-1.4.0.tar.gz
--2016-02-14 19:37:02--  http://ftp.jaist.ac.jp/pub/Apache/drill/drill-1.4.0/Apache-drill-1.4.0.tar.gz
Resolving ftp.jaist.ac.jp (ftp.jaist.ac.jp)... 2001:df0:2ed:feed::feed, 150.65.7.130
Connecting to ftp.jaist.ac.jp (ftp.jaist.ac.jp)|2001:df0:2ed:feed::feed|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 202712816 (193M) [application/x-gzip]
Saving to: ‘Apache-drill-1.4.0.tar.gz’

Apache-drill-1.4.0.tar.gz                 1%[&amp;gt;                                                                              ]   3.25M  5.33MB/s             
Apache-drill-1.4.0.tar.gz               100%[==============================================================================&amp;gt;] 193.32M   743KB/s   in 1m 55s

2016-02-14 19:38:57 (1.68 MB/s) - ‘Apache-drill-1.4.0.tar.gz’ saved [202712816/202712816]

$
$ tar xzvf Apache-drill-1.4.0.tar.gz                                                                                                      
Apache-drill-1.4.0/KEYS
Apache-drill-1.4.0/LICENSE
Apache-drill-1.4.0/README.md
Apache-drill-1.4.0/NOTICE
（中略）
Apache-drill-1.4.0/sample-data/regionsMF/regionsMF_Typed.parquet
Apache-drill-1.4.0/sample-data/regionsSF/regionsSF.parquet
$ cd Apache-drill-1.4.0/
Apache-drill-1.4.0]$
Apache-drill-1.4.0]$ bin/drill-embedded
OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0
Feb 14, 2016 7:40:57 PM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.8 2014-04-29 01:25:26...
Apache drill 1.4.0
&amp;quot;drill baby drill&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なお、初めはt2.microのEC2で試したのですが、メモリ不足？なのかApache Drillが起動しませんでした。メモリ2Gのconohaで試したところ、無事起動しました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ drill-embedded
OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00000006e0000000, 1431633920, 0) failed; error=&#39;Cannot allocate memory&#39; (errno=12)
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (malloc) failed to allocate 1431633920 bytes for committing reserved memory.
# An error report file with more information is saved as:
# /tmp/jvm-10501/hs_error.log
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計元データの作成&#34;&gt;集計元データの作成&lt;/h2&gt;

&lt;p&gt;flowlogs-readerの標準出力をawkでCSV形式にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-13 00:00:00&#39; -e &#39;2016-02-14 00:00:00&#39; | awk -F&amp;quot; &amp;quot; &#39;{print strftime(&amp;quot;%F %T %Z&amp;quot;,$11) &amp;quot;,&amp;quot; $4 &amp;quot;,&amp;quot; $5 &amp;quot;,&amp;quot; $6 &amp;quot;,&amp;quot; $7 &amp;quot;,&amp;quot; $8 &amp;quot;,&amp;quot; $10 &amp;quot;,&amp;quot; $13}&#39; &amp;gt; result.csv    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、CSV形式のままApache Drillで利用すると、以下のような集計できない形になってしまいます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select * from dfs.`/home/xxxxxxxx/result.csv`;                
+------------------------------------------------------------------------------------------------+
|                                            columns                                             |
+------------------------------------------------------------------------------------------------+
| [&amp;quot;time&amp;quot;,&amp;quot;srcaddr&amp;quot;,&amp;quot;dstaddr&amp;quot;,&amp;quot;srcport&amp;quot;,&amp;quot;dstport&amp;quot;,&amp;quot;protocol&amp;quot;,&amp;quot;bytes&amp;quot;,&amp;quot;result&amp;quot;]                   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;44626&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;895&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;44624&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;77&amp;quot;,&amp;quot;ACCEPT&amp;quot;]    |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;54.245.244.135&amp;quot;,&amp;quot;52457&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;56372&amp;quot;,&amp;quot;ACCEPT&amp;quot;]  |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;50.112.250.150&amp;quot;,&amp;quot;49776&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;3262&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;54.245.120.220&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;33586&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;201&amp;quot;,&amp;quot;ACCEPT&amp;quot;]    |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;54.245.244.135&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;52457&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;31877&amp;quot;,&amp;quot;ACCEPT&amp;quot;]  |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;150.67.32.141&amp;quot;,&amp;quot;22&amp;quot;,&amp;quot;39999&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;520&amp;quot;,&amp;quot;ACCEPT&amp;quot;]      |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;50.112.250.150&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;49776&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;5552&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
| [&amp;quot;2016-02-13 18:33:24 JST&amp;quot;,&amp;quot;103.246.150.182&amp;quot;,&amp;quot;172.20.0.10&amp;quot;,&amp;quot;443&amp;quot;,&amp;quot;44629&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;935&amp;quot;,&amp;quot;ACCEPT&amp;quot;]   |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで、CSVファイルの1行目にヘッダを追加し、CSVH形式で保存します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ more /home/xxxxxxxx/result.csvh
time,srcaddr,dstaddr,srcport,dstport,protocol,bytes,result
2016002013 18:33:24 JST,103.246.150.182,172.20.0.10,443,44626,6,895,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,103.246.150.182,44624,443,6,77,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,54.245.244.135,52457,443,6,56372,ACCEPT
2016002013 18:33:24 JST,172.20.0.10,50.112.250.150,49776,443,6,3262,ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;また、ポート番号の欄に&lt;code&gt;-&lt;/code&gt;が入っていると、ポート番号を数値として扱えなくなるため、sedで&lt;code&gt;-&lt;/code&gt;を0に置換しておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i -e &amp;quot;s/-/0/g&amp;quot; /home/xxxxxxxx/result.csvh  
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;集計してみる&#34;&gt;集計してみる&lt;/h2&gt;

&lt;p&gt;とりあえずselectしてみましょう。CSVH形式にすると追加したヘッダがカラムになります。これならば集計できますね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select * from dfs.`/home/xxxxxxxx/result.csvh` ;
+--------------------------+------------------+------------------+----------+----------+-----------+--------+---------+
|           time           |     srcaddr      |     dstaddr      | srcport  | dstport  | protocol  | bytes  | result  |
+--------------------------+------------------+------------------+----------+----------+-----------+--------+---------+
| 2016002013 18:33:24 JST  | 103.246.150.182  | 172.20.0.10      | 443      | 44626    | 6         | 895    | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 103.246.150.182  | 44624    | 443      | 6         | 77     | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 54.245.244.135   | 52457    | 443      | 6         | 56372  | ACCEPT  |
| 2016002013 18:33:24 JST  | 172.20.0.10      | 50.112.250.150   | 49776    | 443      | 6         | 3262   | ACCEPT  |
| 2016002013 18:33:24 JST  | 54.245.120.220   | 172.20.0.10      | 443      | 33586    | 6         | 201    | ACCEPT  |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送信元がVPC内部のアドレス、宛先がVPC外部のアドレス、送信元ポートがウェルノウンポートな通信のバイト数で集計します。VPC外部の端末がサーバの提供するサービスにアクセスしたことによって生じたアウトバウンド通信が対象になるはず。&lt;/p&gt;

&lt;p&gt;上位2件に入った、protocolが41（IPv6）で192.88.99.255宛の通信はいったい何でしょうか。6to4？&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select srcaddr,dstaddr,protocol,srcport,SUM(cast(bytes as INTEGER)) as bytes
. . . . . . . . . . . &amp;gt; from dfs.`/home/xxxxxxxx/result.csvh`    
. . . . . . . . . . . &amp;gt; where srcaddr LIKE &#39;172.20%&#39; AND dstaddr NOT LIKE &#39;172.20%&#39;
. . . . . . . . . . . &amp;gt; AND srcport &amp;lt; 1024
. . . . . . . . . . . &amp;gt; GROUP BY srcaddr,dstaddr,protocol,srcport
. . . . . . . . . . . &amp;gt; ORDER BY bytes desc;
+--------------+-----------------+-----------+----------+--------+
|   srcaddr    |     dstaddr     | protocol  | srcport  | bytes  |
+--------------+-----------------+-----------+----------+--------+
| 172.20.1.52  | 192.88.99.255   | 41        | 0        | 49352  |
| 172.20.0.67  | 192.88.99.255   | 41        | 0        | 48608  |
| 172.20.0.10  | xxx.xxx.xxx.xxx  | 6         | 22       | 20748  |
| 172.20.0.10  | 157.7.236.66    | 17        | 123      | 10488  |
| 172.20.0.20  | 160.16.101.116  | 17        | 123      | 4408   |
| 172.20.0.10  | 129.250.35.250  | 17        | 123      | 1748   |
| 172.20.0.10  | 59.106.180.168  | 17        | 123      | 1748   |
| 172.20.0.10  | 157.7.154.29    | 17        | 123      | 1672   |
| 172.20.0.20  | 60.56.214.78    | 17        | 123      | 1672   |
| 172.20.0.20  | 160.16.201.66   | 17        | 123      | 1672   |
| 172.20.0.20  | 106.187.50.84   | 17        | 123      | 1672   |
| 172.20.0.10  | xxx.xxx.xxx.xxx    | 6         | 22       | 440    |
| 172.20.0.20  | 37.203.214.106  | 6         | 80       | 40     |
| 172.20.0.20  | 107.150.60.74   | 6         | 80       | 40     |
+--------------+-----------------+-----------+----------+--------+
14 rows selected (3.928 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;送信元がVPC内部のアドレス、宛先がVPC外部のアドレス、宛先ポートがウェルノウンポートな通信のバイト数で集計します。サーバが、VPC外部のサーバにアクセスしたことによって生じたアウトバウンド通信が対象になるはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0: jdbc:drill:zk=local&amp;gt; select srcaddr,dstaddr,protocol,dstport,SUM(cast(bytes as INTEGER)) as bytes
. . . . . . . . . . . &amp;gt; from dfs.`/home/xxxxxxxx/result.csvh`
. . . . . . . . . . . &amp;gt; where srcaddr LIKE &#39;172.20%&#39; AND dstaddr NOT LIKE &#39;172.20%&#39;
. . . . . . . . . . . &amp;gt; AND dstport &amp;lt; 1024
. . . . . . . . . . . &amp;gt; GROUP BY srcaddr,dstaddr,protocol,dstport
. . . . . . . . . . . &amp;gt; ORDER BY bytes desc;
+--------------+------------------+-----------+----------+-----------+
|   srcaddr    |     dstaddr      | protocol  | dstport  |   bytes   |
+--------------+------------------+-----------+----------+-----------+
| 172.20.0.10  | 103.246.150.154  | 6         | 443      | 21089910  |
| 172.20.0.10  | 27.0.2.250       | 6         | 443      | 16760457  |
| 172.20.0.10  | 103.246.150.182  | 6         | 443      | 16511551  |
| 172.20.0.10  | 54.245.91.49     | 6         | 443      | 2868271   |
| 172.20.0.10  | 54.244.113.28    | 6         | 443      | 2711682   |
| 172.20.0.10  | 54.245.120.220   | 6         | 443      | 1238373   |
| 172.20.0.10  | 50.112.250.150   | 6         | 443      | 913540    |
| 172.20.0.10  | 54.214.50.176    | 6         | 443      | 627718    |
| 172.20.0.10  | 54.245.244.135   | 6         | 443      | 331731    |
| 172.20.1.52  | 192.88.99.255    | 41        | 0        | 49352     |
| 172.20.0.67  | 192.88.99.255    | 41        | 0        | 48608     |
| 172.20.0.10  | 54.239.25.168    | 6         | 443      | 31625     |
| 172.20.0.10  | 157.7.236.66     | 17        | 123      | 10488     |
| 172.20.0.10  | 72.21.214.87     | 6         | 443      | 4655      |
| 172.20.0.20  | 160.16.101.116   | 17        | 123      | 4408      |
| 172.20.0.10  | 59.106.180.168   | 17        | 123      | 1748      |
| 172.20.0.10  | 129.250.35.250   | 17        | 123      | 1748      |
| 172.20.0.20  | 60.56.214.78     | 17        | 123      | 1672      |
| 172.20.0.20  | 160.16.201.66    | 17        | 123      | 1672      |
| 172.20.0.20  | 106.187.50.84    | 17        | 123      | 1672      |
| 172.20.0.10  | 157.7.154.29     | 17        | 123      | 1672      |
| 172.20.0.10  | 108.168.243.150  | 6         | 443      | 1093      |
| 172.20.0.10  | 54.231.224.66    | 6         | 80       | 769       |
| 172.20.0.10  | 54.231.224.10    | 6         | 80       | 613       |
+--------------+------------------+-----------+----------+-----------+
24 rows selected (0.714 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;VPC Flow Logsを分析する手法として、Apache Drillを試しました。CSVファイルに対してmysqlライクなクエリを投げられるのが大変便利だなと思いました。Apache Drillを使っても自分がやりたいことをクエリにしなければなりませんが、シェル芸のワンライナーを考えるよりもmysqlライクなクエリを考える方が簡単です。&lt;/p&gt;

&lt;p&gt;今回利用したVPC Flow Logsはたった3Mです。データ容量がもっと増えた場合にどのような挙動になるのかは別途確認したいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RedPenで「開いた（平仮名）のほうが読みやすくなる表現一覧」をチェックする</title>
      <link>http://aimless.jp/blog/archives/2016-02-09-check-the-readable-expression-by-redpen</link>
      <pubDate>Tue, 09 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-09-check-the-readable-expression-by-redpen</guid>
      <description>

&lt;p&gt;RedPenのJavaScript拡張を利用して、&lt;a href=&#34;http://www.danshihack.com/2015/06/04/junp/twitter-editter-kana.html&#34;&gt;プロの編集が教える「開いた（平仮名）のほうが読みやすくなる表現一覧」が超勉強になると話題&lt;/a&gt;に乗っている修正事項をチェックしてみました。&lt;/p&gt;

&lt;h2 id=&#34;javascript拡張&#34;&gt;Javascript拡張&lt;/h2&gt;

&lt;p&gt;表現一覧から、日常で使ってしまいそうな表現だけをチェックするようにします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat js/easyReadCheck.js
function validateSentence(sentence) {

  var checkKeywordObj = {
    &#39;更に&#39; : &#39;さらに&#39;,
    &#39;殆ど&#39; : &#39;ほとんど&#39;,
    &#39;下さい&#39; : &#39;ください&#39;,
    &#39;何時か&#39; : &#39;いつか&#39;,
    &#39;事&#39; : &#39;こと&#39;,
    &#39;何時か&#39; : &#39;いつか&#39;,
    &#39;何処か&#39; : &#39;どこか&#39;,
    &#39;何故か&#39; : &#39;なぜか&#39;,
    &#39;後で&#39; : &#39;あとで&#39;,
    &#39;出来るだけ&#39; : &#39;できるだけ&#39;,
    &#39;ひと通り&#39; : &#39;ひととおり&#39;,
    &#39;丁度&#39; : &#39;ちょうど&#39;,
    &#39;時間が経つ&#39; : &#39;時間がたつ&#39;,
    &#39;何でも&#39; : &#39;なんでも&#39;,
  }

  // 各センテンスに対して、checkKeywordObj分処理を実施
  for (var i = 0; i &amp;lt; Object.keys(checkKeywordObj).length; i++) {
    // キーワードを正規表現にセット
    var regex = new RegExp(Object.keys(checkKeywordObj)[i])
    // もしセンテンスの文章がcheckKeywordObjにマッチしたら
    if ( sentence.content.match(regex) ){
      // そのセンテンスが自然言語処理された結果を総当たり
      for (var j = 0; j &amp;lt; sentence.tokens.length; j++) {
        // 自然言語解析の結果とキーワードが一致したらエラーメッセージを出力
        if ( sentence.tokens[j].surface == Object.keys(checkKeywordObj)[i] ){
          addError(&#39;「&#39; + sentence.tokens[j].surface + &#39;」を「&#39; + checkKeywordObj[Object.keys(checkKeywordObj)[i]] + &#39;」に修正してください&#39;, sentence);            
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;テストしてみる&#34;&gt;テストしてみる&lt;/h2&gt;

&lt;p&gt;以下の文章をテストしてみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ごはんの事である。何時かご飯を食べて下さい。

あなたはご飯を食べる事が出来ます。更に、ラーメンを食べることもできます。

事件は会議室で起きてるんじゃない。現場で起きているんだ。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちゃんとエラーになりました。ブログをデプロイしているCircleCIでも使おう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[2016-02-09 01:05:48.540][INFO ] cc.redpen.Main - Configuration file: /home/aimless/study/document/redpen/redpen-distribution-1.4.1/conf/blog.xml
[2016-02-09 01:05:48.549][INFO ] cc.redpen.ConfigurationLoader - Loading config from specified config file: &amp;quot;/home/aimless/study/document/redpen/redpen-distribution-1.4.1/conf/blog.xml&amp;quot;
[2016-02-09 01:05:48.562][INFO ] cc.redpen.ConfigurationLoader - Succeeded to load configuration file
[2016-02-09 01:05:48.563][INFO ] cc.redpen.ConfigurationLoader - Language is set to &amp;quot;ja&amp;quot;
[2016-02-09 01:05:48.563][WARN ] cc.redpen.ConfigurationLoader - No type configuration...
[2016-02-09 01:05:48.564][INFO ] cc.redpen.ConfigurationLoader - No &amp;quot;symbols&amp;quot; block found in the configuration
[2016-02-09 01:05:48.637][INFO ] cc.redpen.config.SymbolTable - &amp;quot;ja&amp;quot; is specified.
[2016-02-09 01:05:48.638][INFO ] cc.redpen.config.SymbolTable - &amp;quot;normal&amp;quot; type is specified
[2016-02-09 01:05:49.178][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[。, ？, ！]&amp;quot; are added as a end of sentence characters
[2016-02-09 01:05:49.178][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[’, ”]&amp;quot; are added as a right quotation characters
[2016-02-09 01:05:49.193][INFO ] cc.redpen.validator.Validator - max_num is set to 1500
[2016-02-09 01:05:49.195][INFO ] cc.redpen.validator.Validator - max_num is not set. Use default value of 5
[2016-02-09 01:05:49.198][INFO ] cc.redpen.validator.JavaScriptValidator - JavaScript validators directory: /home/aimless/study/document/redpen/redpen-distribution-1.4.1/js
test2.md:1: ValidationError[ParagraphNumber], The number of paragraphs exceeds the maximum of 7. at line: 実行
test2.md:12: ValidationError[JavaScript], [spellCheck.js] Fortigateはスペルミスの可能性があります at line: Fortigate
test2.md:14: ValidationError[JavaScript], [spellCheck.js] Javascriptはスペルミスの可能性があります at line: Javascript
test2.md:16: ValidationError[JavaScript], [easyReadCheck.js] 「事」を「こと」に修正してください at line: ごはんの事である。
test2.md:16: ValidationError[JavaScript], [easyReadCheck.js] 「下さい」を「ください」に修正してください at line: 何時かご飯を食べて下さい。
test2.md:18: ValidationError[JavaScript], [easyReadCheck.js] 「事」を「こと」に修正してください at line: あなたはご飯を食べる事が出来ます。
test2.md:18: ValidationError[JavaScript], [easyReadCheck.js] 「更に」を「さらに」に修正してください at line: 更に、ラーメンを食べることもできます。

[2016-02-09 01:05:50.390][ERROR] cc.redpen.Main - The number of errors &amp;quot;7&amp;quot; is larger than specified (limit is &amp;quot;1&amp;quot;).
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>asciidoctor-pdfで複数行のフッタを作る</title>
      <link>http://aimless.jp/blog/archives/2016-02-07-build-multiple-line-footer-by-asciidoctor-pdf</link>
      <pubDate>Sun, 07 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-07-build-multiple-line-footer-by-asciidoctor-pdf</guid>
      <description>

&lt;p&gt;会社のWordテンプレのフッターが複数行なので、asciidoctor-pdfで複数行のフッタを出力する方法を調べました。&lt;/p&gt;

&lt;h2 id=&#34;テーマファイルの書き方&#34;&gt;テーマファイルの書き方&lt;/h2&gt;

&lt;p&gt;今回は、PDFのフッタにページ番号とコピーライトをつけます。その場合、テーマファイルを以下のように記載します。参考：&lt;a href=&#34;https://github.com/asciidoctor/asciidoctor-pdf/blob/master/docs/theming-guide.adoc#running-header--footer&#34;&gt;Running header &amp;amp; footer&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;footer:
  font_size: $base_font_size_small
  font_color: $base_font_color
  border_color: dddddd
  border_width: 0.25
  height: 25mm
  padding: [3mm,0,0,0]
  vertical_align: top
  recto_content:
    center: |
        {page-number} / {page-count} +
        Copyright &amp;amp;#169; hogehoge company CO.,LTD. All right reserved.
  verso_content: |
        {page-number} / {page-count} +
        Copyright &amp;amp;#169; hogehoge company CO.,LTD. All right reserved.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pdf出力&#34;&gt;PDF出力&lt;/h2&gt;

&lt;p&gt;asciidoctor-pdfでビルドする際に上記のテーマファイルを利用すると、以下のPDFが生成されます。やりたいことができました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-02-07-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>flowlogs-readerを使って、VPC Flow Logsをコマンドラインで操作する</title>
      <link>http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader</link>
      <pubDate>Tue, 02 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-02-02-retrieving-aws-vpc-flow-logs-using-flowlogs-reader</guid>
      <description>

&lt;p&gt;VPC Flow Logsを分析、可視化する方法を模索しており、以下のツール・サービスを試しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sumologic&lt;/li&gt;
&lt;li&gt;Splunk&lt;/li&gt;
&lt;li&gt;ElasticSearch&lt;/li&gt;
&lt;li&gt;ElasticSearch Service&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どれも素晴らしいツールなのですが、気軽にログを調査する、集計するといった用途で使うには少々大がかりです。もっと気軽なツールはないかとGithubをさまよった結果、&lt;a href=&#34;https://github.com/obsrvbl/flowlogs-reader&#34;&gt;obsrvbl/flowlogs-reader&lt;/a&gt;というツールを見つけたので試してみました。&lt;/p&gt;

&lt;h2 id=&#34;インストール&#34;&gt;インストール&lt;/h2&gt;

&lt;p&gt;READMEに書いてある通りです。ソースからインストールしてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/obsrvbl/flowlogs-reader.git
cd flowlogs-reader
pyenv exec python setup.py develop
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基本操作&#34;&gt;基本操作&lt;/h2&gt;

&lt;p&gt;READMEに従って、&lt;code&gt;flowlogs_reader logGroupName&lt;/code&gt;を実行してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup

Traceback (most recent call last):
（中略）
botocore.exceptions.ClientError: An error occurred (ResourceNotFoundException) when calling the FilterLogEvents operation: The specified log group does not exist.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そんなロググループはないと怒られました。これはリージョンを指定していないことが原因です。デフォルトのリージョンはus-east-1になっていますが、私のAWSアカウントのus-east-1にはlogGroupNameというVPC Flow Logsが存在しません。東京リージョンにはlogGroupNameというVPC Flow Logsが存在していますので、&lt;code&gt;--region&lt;/code&gt;で東京リージョンを指定します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1       
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 51378 6 13 1982 1454337327 1454337447 ACCEPT OK       
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 47354 6 10 1223 1454337327 1454337447 ACCEPT OK      
2 743065858817 eni-63444414 27.0.2.250 172.20.0.10 443 50540 6 10 935 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 47354 443 6 12 1501 1454337327 1454337447 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 27.0.2.250 50539 443 6 12 1501 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 27.0.2.250 50540 443 6 12 1501 1454337327 1454337387 ACCEPT OK
2 743065858817 eni-63444414 195.99.212.67 172.20.0.10 53 57627 17 1 77 1454337327 1454337387 REJECT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;出ました！なにこれすごい！&lt;/p&gt;

&lt;h3 id=&#34;時間指定&#34;&gt;時間指定&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;-s&lt;/code&gt;と&lt;code&gt;-e&lt;/code&gt;オプションを使うことで、抽出する範囲を限定することができます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39;
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44589 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44589 6 10 935 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44591 6 10 935 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 48618 6 7 1079 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44591 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44592 443 6 6 313 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44588 6 9 895 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 103.246.150.154 172.20.0.10 443 44592 6 4 306 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 54.245.120.220 48618 443 6 11 2232 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 103.246.150.154 44588 443 6 12 1501 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-98fccfd1 104.216.59.132 172.20.0.106 57664 6379 6 1 40 1454324381 1454324411 REJECT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おおお、すごい。VPC Flow Logs内のstartをもとにフィルタリングしてるようです。&lt;/p&gt;

&lt;h2 id=&#34;ipアドレスで抽出&#34;&gt;IPアドレスで抽出&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;findip&lt;/code&gt;を利用することで、IPアドレスを利用したログの抽出が可能です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup findip 54.245.120.220 --region
 ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39;                                                
2 743065858817 eni-63444414 54.245.120.220 172.20.0.10 443 48618 6 7 1079 1454324362 1454324415 ACCEPT OK
2 743065858817 eni-63444414 172.20.0.10 54.245.120.220 48618 443 6 11 2232 1454324362 1454324415 ACCEPT OK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;awkで処理する&#34;&gt;AWKで処理する&lt;/h2&gt;

&lt;p&gt;VPC Flow Logsの内容が標準出力されるということは、AWKで自由に編集できるということです。&lt;/p&gt;

&lt;p&gt;まずは、VPC Flow Logsの時刻をJSTに変換、かつ不要なフィールドを削除することで可読性を向上してみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 -s &#39;2016-02-01 10:59:00&#39; -e &#39;2016-02-01 11:00:00&#39; | awk -F&amp;quot; &amp;quot; &#39;{print strftime(&amp;quot;%F %T %Z&amp;quot;,$11) &amp;quot; &amp;quot; $4 &amp;quot; &amp;quot; $5 &amp;quot; &amp;quot; $6 &amp;quot; &amp;quot;
 $7 &amp;quot; &amp;quot; $10 &amp;quot; &amp;quot; $13}&#39;
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44589 443 1501 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44589 935 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44591 935 ACCEPT
2016-02-01 19:59:22 JST 54.245.120.220 172.20.0.10 443 48618 1079 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44591 443 1501 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44592 443 313 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44588 895 ACCEPT
2016-02-01 19:59:22 JST 103.246.150.154 172.20.0.10 443 44592 306 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 54.245.120.220 48618 443 2232 ACCEPT
2016-02-01 19:59:22 JST 172.20.0.10 103.246.150.154 44588 443 1501 ACCEPT
2016-02-01 19:59:41 JST 104.216.59.132 172.20.0.106 57664 6379 40 REJECT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;すごく見やすくなりました。一般的なファイアウォールのログのようです。この形式であればトラブルシュートが簡単ですね。&lt;/p&gt;

&lt;p&gt;どのようなデータを得られるかは、分析の要件をシェル芸で実装できるかどうか次第です。私はシェル芸力が赤ちゃんレベルなので、Google先生に聞きながら、172.20.0.10からのOutbound通信を、通信量が多いホスト順に集計するワンライナーを書いてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ pyenv exec flowlogs_reader VPCFlowLogGroup --region ap-northeast-1 | awk -F&amp;quot; &amp;quot; &#39;{if($4 ~ /^172.20.0.10$/) print $4 &amp;quot; &amp;quot; $5 &amp;quot; &amp;quot; $6 &amp;quot; &amp;quot; $7 &amp;quot; &amp;quot; $10}&#39; | awk -F &amp;quot; &amp;quot; &#39;{ arr[$2] += $5 } END {for
 (i in arr) {print arr[i] &amp;quot;\t&amp;quot; i } }&#39; | sort -nr
1953728 xxx.246.150.182
1513154 xxx.0.2.250
1403416 xxx.2.107.75
585957  xxx.246.150.154
230835  xxx.245.91.49
99516   xxx.245.231.247
68348   xxx.214.251.251
59299   xxx.112.97.146
29665   xxx.245.120.220
2657    xxx.32.102.213
1368    xxx.7.236.66
684     xxx.106.180.168
228     xxx.7.154.29
228     xxx.250.35.250
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おお、できたっぽい！&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;過去触ってきた各種サービスは、VPC Flow Logsを継続的に保管し、傾向を分析、可視化するにはもってこいです。ですが、トラブルシュートなどのスポット用途でログを見たい、分析したいという用途には少々オーバースペックです。そんな人には、&lt;a href=&#34;https://github.com/obsrvbl/flowlogs-reader&#34;&gt;obsrvbl/flowlogs-reader&lt;/a&gt;をお勧めします。気軽ですよ。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sumologicを使ってVPC Flow Logsを可視化する</title>
      <link>http://aimless.jp/blog/archives/2016-01-24-analysing-vpcflowlogs-by-sumologic</link>
      <pubDate>Sun, 24 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-01-24-analysing-vpcflowlogs-by-sumologic</guid>
      <description>

&lt;h2 id=&#34;vpc-flow-logsを可視化したい&#34;&gt;VPC FLow Logsを可視化したい&lt;/h2&gt;

&lt;p&gt;検証環境のVPC Flow Logsを収集、調査、分析するためにElasticSearch Serviceを利用していましたが、利用料をケチるためにt2.microで動かしていたため動作が遅く困っていました。オンプレミスで十分なリソースを積んだElasticSearchを立ててもよかったのですが、目的はログを分析することであって、ElasticSearchを運用することではありません。&lt;/p&gt;

&lt;p&gt;そこで、VPC FLow Logsに対応しており、無料プランのあるログ分析SaaSを調べたところ、&lt;a href=&#34;https://www.sumologic.com/&#34;&gt;sumologic&lt;/a&gt;が見つかりました。Re:Invent2015の会場で相撲を取っていたあのsumologicです。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&#34;https://www.youtube.com/watch?v=WLuH-Rht3nw&#34;&gt;Sumo wrestling, presented by SumoLogic @ AWS re:Invent2015 Game 3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トライアル期間を利用して、さらっと触ってみた結果をメモしておきます。&lt;/p&gt;

&lt;p&gt;なお、現時点でのプランが30日トライアルのため、sumologicの全機能が利用できる状況です。30日後にフリープランになった場合、このエントリーに記載したことの何ができなくなるのか少々不安です。30日後に確認します。（参考：&lt;a href=&#34;https://www.sumologic.com/pricing/&#34;&gt;Pricing&lt;/a&gt;）&lt;/p&gt;

&lt;h2 id=&#34;sumologicにログを転送する仕組み&#34;&gt;SumoLogicにログを転送する仕組み&lt;/h2&gt;

&lt;p&gt;sumologicにログを転送する方法は2つあります。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;詳細&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;installed Collector&lt;/td&gt;
&lt;td&gt;自前のサーバ上にインストールするコレクター。サーバにエージェントが常駐する&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hosted Collector&lt;/td&gt;
&lt;td&gt;sumologic上にホストされているコレクター。サーバにエージェントをインストールする必要なし&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;詳細は&lt;a href=&#34;https://service.sumologic.com/help/Default.htm#Difference_between_Collectors.htm%3FTocPath%3DSending%2520Data%7CCollectors%7C_____1&#34;&gt;What&amp;rsquo;s the difference between Collector types?&lt;/a&gt;を参照ください。&lt;/p&gt;

&lt;p&gt;Hosted CollectorはデフォルトでAWSの以下サービスに対応しています。残念なことに、現時点でVPC Flow Logsには未対応です。（VPC Flow LogsをS3に吐き出せば、そのログを取得できるかもしれません）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;S3&lt;/li&gt;
&lt;li&gt;ELB&lt;/li&gt;
&lt;li&gt;CloudFront&lt;/li&gt;
&lt;li&gt;CloudTrail&lt;/li&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;li&gt;S3 Audit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;sumologicにvpc-flow-logsを送る方法&#34;&gt;sumologicにVPC Flow Logsを送る方法&lt;/h2&gt;

&lt;p&gt;公式のヘルプ(&lt;a href=&#34;https://service.sumologic.com/help/Default.htm#Collecting_Amazon_VPC_Flow_Logs.htm%3FTocPath%3DApps%7CSumo%2520Logic%2520App%2520for%2520Amazon%2520VPC%2520Flow%2520Logs%7C_____1&#34;&gt;Collecting Amazon VPC Flow Logs&lt;/a&gt;)に従い、installed Collectorを利用したログ転送を試したのですが、以下のエラーが出てしまい上手く行きませんでした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016-01-22 17:39:29,994 10946 [pool-2-thread-4] INFO com.amazonaws.internal.DefaultServiceEndpointBuilder  - {logs, ap-southeast-1} was not found in region metadata, trying to construct an endpoint using the standard pattern for this region: &#39;logs.ap-southeast-1.amazonaws.com&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そこで今回は、sumologicのgithubリポジトリで公開されているLambdaファンクション（&lt;a href=&#34;https://github.com/SumoLogic/sumologic-aws-lambda/tree/master/cloudwatchlogs&#34;&gt;SumoLogic/sumologic-aws-lambda&lt;/a&gt;）を利用することにしました。このLambdaファンクションは、VPC Flow Logsに特化したものではなく、sumologicのAPIを利用してCloudWatch Logsをsumologicに送るものです。そのため、VPC Flow Logs以外でも利用可能です。&lt;/p&gt;

&lt;p&gt;なお、sumologicのAPI（Collector Management API）は、PROFESSIONALプラン以上で利用可能です。そのため、FREEプランでは利用できません。。。&lt;/p&gt;

&lt;h2 id=&#34;sumologicにログを送る&#34;&gt;sumologicにログを送る&lt;/h2&gt;

&lt;p&gt;Hosted Collectorを作成します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-002.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したHosted Collectorに、HTTPSでデータを投入できるAPIエンドポイントを追加します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-008.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-009.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-007.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-004.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;作成したエンドポイントの情報を元に&lt;a href=&#34;https://github.com/SumoLogic/sumologic-aws-lambda/tree/master/cloudwatchlogs&#34;&gt;SumoLogic/sumologic-aws-lambda&lt;/a&gt;の内容を修正して、Lambdaファンクションを作ります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-005.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最後に、作成したLambdaファンクションをVPC Flow LogsのSubscriptionに追加します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-006.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ログを可視化する&#34;&gt;ログを可視化する&lt;/h2&gt;

&lt;p&gt;sumologicには標準でVPC Flow Logsを可視化するAppsが用意されています。とりあえずこれを利用します。FREEプランになっても使えるかは要確認です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-010.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Appには複数のダッシュボードとクエリが定義されています。とりあえずActivityなるダッシュボードを見てみます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-011.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-012.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;超カッコいい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-013.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;ログを検索する&#34;&gt;ログを検索する&lt;/h2&gt;

&lt;p&gt;独自のクエリ言語を利用して、ログを検索することができます。&lt;/p&gt;

&lt;p&gt;取り込んだVPC Flow Logsを送信元IPアドレスで限定して、送信元IPアドレスと宛先IPアドレスで分類して転送バイトを合計、さらに合計値でソートしてみます。アウト方向の転送量が多い通信を特定するクエリをイメージしています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_sourceCategory=xxxx_vpcflowlogs message
| json &amp;quot;message&amp;quot;,&amp;quot;logStream&amp;quot;,&amp;quot;logGroup&amp;quot;
| parse field=message &amp;quot;* * * * * * * * * * * * * *&amp;quot; as version,accountID,interfaceID,src_ip,dest_ip,src_port,dest_port,Protocol,Packets,bytes,StartSample,EndSample,Action,status
| where src_ip = &amp;quot;172.20.0.10&amp;quot;
| sum(bytes) group by src_ip,dest_ip
| sort by _sum
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;クエリの結果が、下の方に表示されています。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-014.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結果をCSVでダウンロードすることもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-015.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結果をグラフにすることもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-016.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;さらに結果をダッシュボードに追加することもできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-017.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2016-01-24-018.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;雑な所感&#34;&gt;雑な所感&lt;/h2&gt;

&lt;p&gt;有料のSaaSだけあってかなり使いやすいです。また、Hosted Collectorを利用することで、サーバレスでAWSの各種ログを収集・分析することができます。今後、AWSのログを保存・分析するための基盤のお仕事があった場合、検討候補にしたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Amazon WorkSpacesを不便にする</title>
      <link>http://aimless.jp/blog/archives/2016-01-23-inconvenient-workspaces</link>
      <pubDate>Sat, 23 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2016-01-23-inconvenient-workspaces</guid>
      <description>

&lt;p&gt;WorkSpacesは大変気軽です。ですが、リモートアクセス用途での導入を検討した場合、あまりにも気軽に社内LANにアクセスできてしまうことが問題となります。標準の設定のまま利用者に使わせると、社内LANに新たなリスクを生み出すことになります。&lt;/p&gt;

&lt;p&gt;もう少し不便にすることでセキュリティを高められないか、と考え、WorkSpacesのセキュリティや監査に関する機能を調査したのでメモします。
なお多要素認証については当たり前なので触れません。&lt;/p&gt;

&lt;h2 id=&#34;認証情報の記憶を無効化する&#34;&gt;認証情報の記憶を無効化する&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントは、認証情報を記憶する機能（Remember Me）があります。これを利用することで、次回以降のログインにおいてIDとパスワードの入力が不要となります。多要素認証を使っている場合、多要素認証のパスワードも記憶します。&lt;/p&gt;

&lt;p&gt;この機能は大変便利ですが、社外からのリモートアクセス用途の場合、第三者による不正利用のリスクが生まれます。この機能は利用しているDirectory Service単位で無効にすることができます。詳細は&lt;a href=&#34;http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me/&#34;&gt;Amazon WorkSpacesのRemember Me機能を使う&lt;/a&gt;を参照ください。&lt;/p&gt;

&lt;h2 id=&#34;利用状況を記録する&#34;&gt;利用状況を記録する&lt;/h2&gt;

&lt;p&gt;リモートアクセス用途の場合、有事の際に備えて、いつ誰が使っていたかをロギングできることが望ましいでしょう。&lt;/p&gt;

&lt;p&gt;AWSでロギングといえばCloudTrailですが、WorkSpacesの利用状況はCloudTrailでロギングされません。WorkSpacesクライアントがWorkSpacesに接続する際にAPI Callが行われないからです。そのかわり、CloudWatchの以下メトリックに利用状況に関するデータが保存されています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ConnectionFailure&lt;/li&gt;
&lt;li&gt;ConnectionSuccess&lt;/li&gt;
&lt;li&gt;InSessionLatency&lt;/li&gt;
&lt;li&gt;SessionDisconnect&lt;/li&gt;
&lt;li&gt;SessionLaunchTime&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CloudWatchにはWorkSpaces単位でメトリックが保存されます。原則、WorkSpacesは1ユーザ1端末ですので、いつ誰がWorkSpacesを利用したかが記録されていると言ってもいいでしょう。ただし、CloudWatchのデータは2週間しか保存されませんので、長期間の保存（例えば13か月分）が必要な場合は、APIを利用して外部のサーバにデータを記録しなけばなりません。&lt;/p&gt;

&lt;p&gt;なお、現時点で、どこから（送信元IPアドレス）と、どの端末（WorkSpacesクライアントがインストールされている環境）からを調べることはできません。実装されるとうれしいです。&lt;/p&gt;

&lt;h2 id=&#34;情報漏えいを防ぐ&#34;&gt;情報漏えいを防ぐ&lt;/h2&gt;

&lt;p&gt;デフォルトのAmazon WorkSpacesは、クリップボードのリダイレクトが有効になっています。WorkSpacesでコピーしたものを、WorkSpacesクライアントが動作するPCにペーストすることができます。リモートアクセス用途でWorkSpacesを利用している場合、技術的には、悪意あるユーザが情報を漏洩させることができます。&lt;/p&gt;

&lt;p&gt;Amazon WorkSpacesがAD ConnectorによってActive Directoryの管理下にある場合、グループポリシを利用して以下の機能を制限することができます。これにより、WorkSpaces内のデータを外部に持ち出されるリスクを極小化することができます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;クリップボードによるコピペ&lt;a href=&#34;http://docs.aws.amazon.com/workspaces/latest/adminguide/group_policy.html#gp_clipboard&#34;&gt;(Clipboard Redirection)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ローカルプリンタを利用した印刷&lt;a href=&#34;http://docs.aws.amazon.com/workspaces/latest/adminguide/group_policy.html#gp_local_printers&#34;&gt;(Local Printer Support)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;不要なセッションを積極的に切断する&#34;&gt;不要なセッションを積極的に切断する&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントは、ネットワークが切れない限りセッションを維持します。所謂アイドルタイムアウトがないようです。リモートアクセス用途の場合、使っていないのに社内LANへのアクセス口が有効になっていることはリスクです。&lt;/p&gt;

&lt;p&gt;現時点で、アイドルタイムアウトの設定は、WorkSpacesのサービス単体では実装できません。ただし、WorkSpacesがAD ConnectorによってActive Directoryの管理下にある場合、グループポリシによってアイドルタイムアウトの設定を行うことが可能です。具体的な設定は以下URLを参照ください。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://technet.microsoft.com/ja-jp/library/cc758177%28v=ws.10%29.aspx&#34;&gt;切断されたセッション、アクティブなセッション、およびアイドル状態のセッションに対するタイムアウト値を設定する&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;

&lt;p&gt;これまでの設定を実施すると、以下のようなWorkSpacesが完成します。かなり不便になりました。ですが、WorkSpacesをリモートアクセス用途で使う場合のリスクを大幅に軽減することができました。満足。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;利用するたびに、多要素認証でログインする必要がある&lt;/li&gt;
&lt;li&gt;いつ使ったか、モニタリングできる&lt;/li&gt;
&lt;li&gt;画面転送しかできない&lt;/li&gt;
&lt;li&gt;使っていないと、接続が切れる&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Amazon WorkSpacesのRemember Me機能を使う</title>
      <link>http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me</link>
      <pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2015-12-15-aws-workspaces-with-remember-me</guid>
      <description>

&lt;p&gt;Amazon WorkSpacesへの憧れが止まりません。BYOD＋WorkSpacesで仕事がしたい。とはいえ、古きSIerである弊社において、いきなりBYODはレベルが高すぎます。そこで、自宅からのリモートアクセス用途として会社に対してWorkSpacesを提案することにしました。そのために色々と調べたのでメモしておきます。&lt;/p&gt;

&lt;h2 id=&#34;mfaの罠&#34;&gt;MFAの罠&lt;/h2&gt;

&lt;p&gt;AD ConnectorとRADIUSサーバによる多要素認証を使ってみて気が付いたのですが、WorkSpacesクライアントは多要素認証を使っていても認証情報を記憶します。多要素認証でログインした後に一旦切断しても、以下の画面になりボタン一つで簡単に再接続ができます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.amazonwebservices.com/blog/2015/ws_client_reconnect_2.png&#34; alt=&#34;https://media.amazonwebservices.com/blog/2015/ws_client_reconnect_2.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;　認証情報を保存する機能は便利なのですが、社外に配置するPCで利用するWorkSpacesクライアントには認証情報を保存したくありません。誰が触るかわかりませんので。&lt;/p&gt;

&lt;h2 id=&#34;remember-meの無効化&#34;&gt;Remember Meの無効化&lt;/h2&gt;

&lt;p&gt;ドキュメントを調べたところ、ぴったりな機能がありました。Remember Meの無効化です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ja_jp/workspaces/latest/adminguide/osx_client_help.htm&#34;&gt;Amazon WorkSpaces クライアントのヘルプ&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Amazon WorkSpaces 管理者が [Remember Me] 機能を無効にしていない場合、それ以降 WorkSpace に簡単に接続できるように、自分の認証情報を安全に保存しておくかどうかを確認するメッセージが表示されます。認証情報は、ユーザーの Kerberos チケットの最大有効期間が終了するまで安全にキャッシュに保存されます。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;現時点で、Remember Meの無効化はサポートにお願いする必要があります。マネジメントコンソールでは無効にできません。&lt;/p&gt;

&lt;h2 id=&#34;remember-me無効後の動作&#34;&gt;Remember Me無効後の動作&lt;/h2&gt;

&lt;p&gt;WorkSpacesクライアントを切断します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-002.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-002.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;切断後の画面がRecconectになりません。IDとパスワード、ワンタイムパスワードを入力する画面に戻りました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-003.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-003.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;WorkSpacesクライアントのオプション設定でもRemember Meを有効にすることができなくなります。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/2015-12-15-004.png&#34; alt=&#34;http://aimless.jp/blog/images/2015-12-15-004.png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;WorkSpacesはどこでもどんな端末でも使えるのが最大のメリットだと思います。ですが、どこでも使える端末に社内ネットワークにアクセスするための認証情報を保存するのはリスクがあります。Remember Meの無効化は、利便性とセキュリティを両立させる良いオプションだと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CircleCIでRedPenを動かす</title>
      <link>http://aimless.jp/blog/archives/2686</link>
      <pubDate>Wed, 25 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2686</guid>
      <description>

&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://aimless.jp/blog/archives/2685/&#34;&gt;RedPenにスペルチェック機能を追加する&lt;/a&gt;の続きです。CircleCI上でRedPenを動かしてみました。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;RedPenを利用したスペルチェックがローカル環境で動くことを確認しました。JavaScriptでチェック項目を拡張できるのがいいですね。次はスペルチェック用辞書の単語を増やした上で、CircleCI上で動作させてみようと思います。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;コンテナの仕込み&#34;&gt;コンテナの仕込み&lt;/h2&gt;

&lt;p&gt;CircleCIのコンテナでRedPenを動かさなければなりません。RedPenはJava 1.8が必要なのでcircle.ymの&lt;code&gt;machine&lt;/code&gt;の箇所に追加します。また、RedPenそのものをダウンロードしなければなりませんので、&lt;code&gt;dependencies&lt;/code&gt;の箇所でアーカイブのダウンロードと展開、削除を行います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-circle.yml&#34;&gt;machine:
  timezone: Asia/Tokyo
  java:
    version: oraclejdk8

dependencies:
  pre:
    - wget https://github.com/RedPen-cc/RedPen/releases/download/v1.4.1/RedPen-1.4.1.tar.gz
    - tar xvf RedPen-1.4.1.tar.gz
    - rm RedPen-1.4.1.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;テストの仕込み&#34;&gt;テストの仕込み&lt;/h2&gt;

&lt;p&gt;RedPenで独自JavaScriptを利用するためには、設定ファイルとJavaScriptファイルが必要です。せっかくなので、これらもリポジトリで管理します。ブログ用リポジトリにRedPenの設定ファイルとスペルチェック用JavaScriptを配置します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/20151125-01.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;circle.yml上でテスト方法を定義する必要があるのですが、「直近の変更が.mdファイルの時だけテストを実行する」という書き方が分かりませんでした。そこで、circle.ymlでは「直近の変更が.mdファイルの時だけテストを実行する」というスクリプトを実行することにしました。&lt;/p&gt;

&lt;p&gt;今回は以下のテストスクリプトを利用します。主に2つの作業を行っています。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ブログ用リポジトリからダウンロードしたRedPenの設定ファイルと独自JavaScriptを、RedPen指定のディレクトリに移動する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git diff&lt;/code&gt;で直近の変更の差分からファイル名のみ取得し、そのファイル名が.mdであればそのファイルに対してRedPenによるテストを実行する&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
mv RedPen/blog.xml RedPen-*/conf
mv RedPen/spellCheck.js RedPen-*/js

filename=`git diff HEAD^ HEAD --name-only`

if [[ $filename =~ .*\.md$ ]] ;then
    echo &amp;quot;start to test $filename....&amp;quot;
    RedPen-*/bin/RedPen -c RedPen-*/conf/blog.xml -f markdown $filename
else
    echo &amp;quot;$filename is not markdown. The test will not be performed.&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;そして、circle.ymlのテストの項目でスクリプトの実行を定義します。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test:
  post:
      - chmod 744 test-redpen.sh
      - bash ./test-redpen.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;実行&#34;&gt;実行&lt;/h3&gt;

&lt;p&gt;さて、試してみます。書きかけのこのエントリをブログ用リポジトリにプッシュしてみます。slackからテスト結果の通知があるまで、艦これでもやりつつ待ちます。&lt;/p&gt;

&lt;p&gt;テストは失敗しました。RedPenのチェックによって、以下4点のエラーが出ました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;RedPenはスペルミスの可能性があります&lt;/li&gt;
&lt;li&gt;JavaScriptはスペルミスの可能性があります&lt;/li&gt;
&lt;li&gt;The length of the sentence (116) exceeds the maximum of 100. at line&lt;/li&gt;
&lt;li&gt;Found invalid Katakana end-hypen &amp;ldquo;エントリ&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/20151125-02.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/20151125-03.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;リトライ&#34;&gt;リトライ&lt;/h2&gt;

&lt;p&gt;4項目を修正しまして再プッシュしましたが、再びエラーです。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The number of paragraphs exceeds the maximum of 6. at line: 実行&lt;/li&gt;
&lt;li&gt;The length of the sentence (109) exceeds the maximum of 100. at line: &amp;mdash;title: CircleCIでRedPenを動かすauthor: kongou_aelayout: postdate: 2015-11-25url: /blog/archives/2686categories:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1つ目のエラーを見ると、1セクションあたりのパラグラフが多いことが原因のようです。そこで、文章の構成を変更しパラグラフの数を減らします。&lt;/p&gt;

&lt;p&gt;2つ目のエラーを見ると、1センテンスあたりの文字数が100を超えていることが原因のようです。しかし、怒られた箇所はHUGOの設定箇所のため、記載方法を変更できません。仕方がないので、標準の&lt;code&gt;SentenceLength&lt;/code&gt;の変則版を自前で実装します。JavaScriptによる拡張、便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  // HUGOの設定以外のセンテンスに対して、100文字を超えているかどうかチェック
  if (sentence.content.match(/^---title.*categories:$/)){
  } else if (sentence.content.length &amp;gt; 100){
    addError(&#39;このセンテンスは100文字を超えています&#39;, sentence);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再度プッシュします。無事テストが通り、エントリが公開されました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/20151125-04.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://aimless.jp/blog/images/20151125-05.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;CircleCIを利用して、ブログに対する継続的なテストを実装することができました。やりたいことができたので満足です。ブログを書きながら、スペルチェック用の辞書を育てていこうとおもいます。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RedPenにスペルチェック機能を追加する</title>
      <link>http://aimless.jp/blog/archives/2685</link>
      <pubDate>Mon, 23 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2685</guid>
      <description>

&lt;h2 id=&#34;前置き&#34;&gt;前置き&lt;/h2&gt;

&lt;p&gt;もともとこのブログはWordpressで運用していました。ですが、アウトプットすることが目的であってCMSを運用することは目的ではありませんので、HUGO + Github Pagesの構成に切り替えました。&lt;/p&gt;

&lt;p&gt;切り替えに伴い、ブログ用のGithubリポジトリにMarkdownをPushすると、CircleCIがHUGOを使ってブログをビルドし、HTMLをGithub PagesにPushする、という仕組みにしました。&lt;/p&gt;

&lt;h2 id=&#34;文章をテストする&#34;&gt;文章をテストする&lt;/h2&gt;

&lt;p&gt;ブログを公開するプロセスにCircleCIがいますので、ブログの文章に対してCIを行うことがでいます。何をするか考えた結果、文章をテストすることにしました。ブログ用のGithubリポジトリにPushされたMarkdownをCircleCIでテストし、誤記や文法の誤りなどがあればテスト失敗とみなしビルドを行わない。こうすることで、ブログに誤った情報を含むエントリーが乗ってしまう可能性を減らすことができます。&lt;/p&gt;

&lt;p&gt;文章をテストするツールを探してみると、&lt;a href=&#34;https://github.com/textlint/textlint&#34;&gt;textlint/textlint&lt;/a&gt;と&lt;a href=&#34;https://github.com/redpen-cc/redpen/&#34;&gt;redpen-cc/redpen&lt;/a&gt;が見つかりました。asciidocとasciidocter-pdfを利用した気軽なドキュメント作成を模索していることもありますので、今回はasciidocをサポートするRedPenを使うことにします。&lt;/p&gt;

&lt;h2 id=&#34;実践&#34;&gt;実践&lt;/h2&gt;

&lt;p&gt;UTM製品であるフォーティゲートの正しいスペルは「FortiGate」です。FortigateやFroutigateではありません。ネットワークエンジニアとして、ネットワーク機器のスペルを間違えるのは恥ずかしい。そこでRedPenに、自分が指定するキーワードを利用したスペルチェック機能を実装します。&lt;/p&gt;

&lt;p&gt;RedPenはJavaScriptを利用した機能拡張をサポートしています。「&lt;a href=&#34;http://www.clear-code.com/blog/2015/8/29.html&#34;&gt;RedPenのValidatorをJavaScript で書くには&lt;/a&gt;」を参考に、JavaScriptによる機能拡張を実装します。&lt;/p&gt;

&lt;p&gt;スペルチェックについては編集距離を利用します。編集距離を求める関数は「&lt;a href=&#34;http://lostlinksearch.net/blog/2012/12/javascript%E3%81%A7%E7%B7%A8%E9%9B%86%E8%B7%9D%E9%9B%A2%EF%BC%88%E3%83%AC%E3%83%BC%E3%83%99%E3%83%B3%E3%82%B7%E3%83%A5%E3%82%BF%E3%82%A4%E3%83%B3%E8%B7%9D%E9%9B%A2%EF%BC%89%E3%82%92%E8%A8%88%E7%AE%97/&#34;&gt;JavaScriptで編集距離（レーベンシュタイン距離）を計算する&lt;/a&gt;
」をそのまま使わせていただきます。&lt;/p&gt;

&lt;p&gt;以下コードの通り、RedPenが検知した名詞とスペルチェックの確認対象との編集距離を求め、0ではなく3以下であればスペルミスとみなします。編集距離を３としたのは勢いです。適当な値はこれから模索していきます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function validateSentence(sentence) {

  var levenshteinDistance = function(a, b) {
    var matrix = new Array(a.length + 1);
    for (var i = 0; i &amp;lt; a.length + 1; i++) {
      matrix[i] = new Array(b.length + 1);
    }

    for (var i = 0; i &amp;lt; a.length + 1; i++) {
      matrix[i][0] = i;
    }

    for (var j = 0; j &amp;lt; b.length + 1; j++) {
      matrix[0][j] = j;
    }

    for (var i = 1; i &amp;lt; a.length + 1; i++) {
      for (var j = 1; j &amp;lt; b.length + 1; j++) {
        var x = a[i - 1] == b[j -1] ? 0 : 1;
        matrix[i][j] = Math.min(
          matrix[i - 1][j] + 1,
          matrix[i][j - 1] + 1,
          matrix[i - 1][j- 1] + x
        );
      }
    }

    return matrix[a.length][b.length];
  }


  console = {
      log: print,
      warn: print,
      error: print
  };

  var checkKeywordArray = [
    &#39;FortiGate&#39;,
    &#39;メルセデスベンツ&#39;,
    &#39;BIG-IP&#39;,
    &#39;インデックス&#39;,
    &#39;JavaScript&#39;
  ]

  for (var i = 0; i &amp;lt; sentence.tokens.length; i++) {
    // 名詞だけを対象に
    if (sentence.tokens[i].tags[0] == &#39;名詞&#39;) {
      for (var j=0; j &amp;lt; checkKeywordArray.length; j++) {
        //console.log(&#39;checking : &#39; + sentence.tokens[i].surface + &#39; and &#39; + checkKeywordArray[j])
        var dist = levenshteinDistance(sentence.tokens[i].surface,checkKeywordArray[j])        
        //console.log(sentence.tokens[i].surface +&#39; is &#39; + dist)
        if (dist &amp;lt;= 3 &amp;amp;&amp;amp; dist != 0){
          addError(sentence.tokens[i].surface + &#39;はスペルミスの可能性があります&#39;, sentence);
        }
      }
    }  
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JavaScriptを利用したvalidatorをRedPenのコンフィグで有効にします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat conf/redpen-conf-ja-custom.xml                                   
&amp;lt;redpen-conf lang=&amp;quot;ja&amp;quot;&amp;gt;
    &amp;lt;validators&amp;gt;
        &amp;lt;validator name=&amp;quot;SentenceLength&amp;quot;&amp;gt;
            &amp;lt;property name=&amp;quot;max_len&amp;quot; value=&amp;quot;100&amp;quot;/&amp;gt;
        &amp;lt;/validator&amp;gt;
        &amp;lt;validator name=&amp;quot;KatakanaEndHyphen&amp;quot;/&amp;gt;
        &amp;lt;validator name=&amp;quot;SectionLength&amp;quot;&amp;gt;
            &amp;lt;property name=&amp;quot;max_num&amp;quot; value=&amp;quot;1500&amp;quot;/&amp;gt;
        &amp;lt;/validator&amp;gt;
        &amp;lt;validator name=&amp;quot;ParagraphNumber&amp;quot;/&amp;gt;
        &amp;lt;validator name=&amp;quot;SuccessiveWord&amp;quot; /&amp;gt;
        &amp;lt;validator name=&amp;quot;JavaScript&amp;quot; /&amp;gt;　　
    &amp;lt;/validators&amp;gt;
&amp;lt;/redpen-conf&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストするMarkdownは以下の通りです。あえて誤記をまぜます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ more test.md

## どうだー

インデックスは正しいです

インデデクスは間違っています

メルセデスベンスは間違っています

メルセデスベンツは正しいです

FortiGateは正しいです

Fortigateは間違っています

Frotigateも間違っています
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;テストします。間違ったスペルのセンテンスだけをエラーとして検知していますね。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redpen-distribution-1.4.1]$ bin/redpen -c conf/redpen-conf-ja-custom.xml -f markdown test.md
[2015-11-23 18:55:02.902][INFO ] cc.redpen.Main - Configuration file: /home/aimless/study/document/redpen/redpen-distribution-1.4.1/conf/redpen-conf-ja-custom.xml
[2015-11-23 18:55:02.910][INFO ] cc.redpen.ConfigurationLoader - Loading config from specified config file: &amp;quot;/home/aimless/study/document/redpen/redpen-distribution-1.4.1/conf/redpen-conf-ja-custom.xml&amp;quot;
[2015-11-23 18:55:02.921][INFO ] cc.redpen.ConfigurationLoader - Succeeded to load configuration file
[2015-11-23 18:55:02.921][INFO ] cc.redpen.ConfigurationLoader - Language is set to &amp;quot;ja&amp;quot;
[2015-11-23 18:55:02.921][WARN ] cc.redpen.ConfigurationLoader - No type configuration...
[2015-11-23 18:55:02.922][INFO ] cc.redpen.ConfigurationLoader - No &amp;quot;symbols&amp;quot; block found in the configuration
[2015-11-23 18:55:02.990][INFO ] cc.redpen.config.SymbolTable - &amp;quot;ja&amp;quot; is specified.
[2015-11-23 18:55:02.990][INFO ] cc.redpen.config.SymbolTable - &amp;quot;normal&amp;quot; type is specified
[2015-11-23 18:55:03.497][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[。, ？, ！]&amp;quot; are added as a end of sentence characters
[2015-11-23 18:55:03.498][INFO ] cc.redpen.parser.SentenceExtractor - &amp;quot;[’, ”]&amp;quot; are added as a right quotation characters
[2015-11-23 18:55:03.512][INFO ] cc.redpen.validator.Validator - max_len is set to 100
[2015-11-23 18:55:03.515][INFO ] cc.redpen.validator.Validator - max_num is set to 1500
[2015-11-23 18:55:03.516][INFO ] cc.redpen.validator.Validator - max_num is not set. Use default value of 5
[2015-11-23 18:55:03.519][INFO ] cc.redpen.validator.JavaScriptValidator - JavaScript validators directory: /home/aimless/study/document/redpen/redpen-distribution-1.4.1/js
test.md:1: ValidationError[ParagraphNumber], The number of paragraphs exceeds the maximum of 7. at line: どうだー
test.md:5: ValidationError[JavaScript], [spellcheck.js] インデデクスはスペルミスの可能性があります at line: インデデクスは間違っています
test.md:7: ValidationError[JavaScript], [spellcheck.js] メルセデスベンスはスペルミスの可能性があります at line: メルセデスベンスは間違っています
test.md:13: ValidationError[JavaScript], [spellcheck.js] Fortigateはスペルミスの可能性があります at line: Fortigateは間違っています
test.md:15: ValidationError[JavaScript], [spellcheck.js] Frotigateはスペルミスの可能性があります at line: Frotigateも間違っています

[2015-11-23 18:55:04.483][ERROR] cc.redpen.Main - The number of errors &amp;quot;5&amp;quot; is larger than specified (limit is &amp;quot;1&amp;quot;).
[aimless@dev redpen-distribution-1.4.1]$
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;所感&#34;&gt;所感&lt;/h2&gt;

&lt;p&gt;RedPenを利用したスペルチェックがローカル環境で動くことを確認しました。JavaScriptでチェック項目を拡張できるのがいいですね。次はスペルチェック用辞書の単語を増やした上で、CircleCI上で動作させてみようと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>aws2excelを作ってみた</title>
      <link>http://aimless.jp/blog/archives/2684</link>
      <pubDate>Sun, 15 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>http://aimless.jp/blog/archives/2684</guid>
      <description>

&lt;h2 id=&#34;作ったもの&#34;&gt;作ったもの&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kongou-ae/aws2excel&#34;&gt;kongou-ae/aws2excel&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AWSの構成情報をxlsxファイルに書き出すスクリプトです。出力されるファイルのイメージはREADMEの画像を参照ください。勢いでやっつけているので、一部サービスにのみ対応しています。最終的にはLambdaで動かしてs3にExcelを吐き出す実装にしたい。&lt;/p&gt;

&lt;h2 id=&#34;経緯&#34;&gt;経緯&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; cloud2excel!&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660383609283457024&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; 残念ながら夢の中のお話です…&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660384559700176896&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/ishikawa84g&#34;&gt;@ishikawa84g&lt;/a&gt; ごめんなさい…ごめんなさいｗ&lt;/p&gt;&amp;mdash; 前佛 雅人(M.Zembutsu) (@zembutsu) &lt;a href=&#34;https://twitter.com/zembutsu/status/660384991096868865&#34;&gt;2015, 10月 31&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;自分もワクワクしながらcloud2excelを検索しまして、、、無いのであれば、勉強がてら作ってみようということで作ってみました。&lt;/p&gt;

&lt;h2 id=&#34;実装&#34;&gt;実装&lt;/h2&gt;

&lt;p&gt;aws-sdkを利用してAPIを叩き必要な情報を取得し、その情報をExcel に書き出しているだけです。Excelへの書き出しは&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;を使いました。&lt;/p&gt;

&lt;h2 id=&#34;雑感&#34;&gt;雑感&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;を見つけたのが今回の最大の収穫です。配列やオブジェクトの情報を、かなり簡単に表形式でExcelに書き出すことができます。さらに、&lt;a href=&#34;https://github.com/guyonroche/exceljs&#34;&gt;guyonroche/exceljs&lt;/a&gt;は、Excelからの読み込みもできるようなので、Infrastrucrture as Excelが実現できます。Excelでパラメータシートを作り、そこにパラメータを書くとAWS上にインスタンスができる。なんという黒魔術。やりませんけど。。。&lt;/p&gt;

&lt;p&gt;また、Node.jsの非同期処理に苦戦しました。async.jsを使っており期待する動作はしているものの、正しい使い方かどうか不安です。Node.js（というかJavascript）を体系的に学びたい。&lt;/p&gt;

&lt;p&gt;今後は、issueにもある通り、コードを分割してメンテナンス性を高め、ELBやRDSなどメジャーなサービスに対応しようと思います。仕事の本業はAWSではないので、プライベートで淡々とメンテしていきます。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>